{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:42:43.433210Z",
     "start_time": "2020-02-07T05:42:42.247468Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiden/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n",
      "1.3.1\n",
      "GeForce RTX 2070 SUPER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[1]:\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "import glob\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import gc\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import json\n",
    "from typing import NamedTuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingWarmRestarts\n",
    "print(torch.__version__)\n",
    "# from tools import eval_summary, save_feature_importance, merge_preds\n",
    "from tools import EarlyStopping\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:42:43.436835Z",
     "start_time": "2020-02-07T05:42:43.434599Z"
    }
   },
   "outputs": [],
   "source": [
    "train_folder = 'data/train/'\n",
    "test_folder = 'data/test/'\n",
    "train_label_path = 'data/train_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:42:43.461106Z",
     "start_time": "2020-02-07T05:42:43.438330Z"
    }
   },
   "outputs": [],
   "source": [
    "train_list = os.listdir(train_folder)\n",
    "test_list = os.listdir(test_folder)\n",
    "train_label = pd.read_csv(train_label_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:42:43.468844Z",
     "start_time": "2020-02-07T05:42:43.462520Z"
    }
   },
   "outputs": [],
   "source": [
    "num_class = len(train_label['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:42:43.474802Z",
     "start_time": "2020-02-07T05:42:43.470038Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모든 csv 파일의 상태_B로 변화는 시점이 같다라고 가정\n",
    "# 하지만, 개별 csv파일의 상태_B로 변화는 시점은 상이할 수 있음\n",
    "def data_loader_all_v2(func, files, folder='', train_label=None, event_time=10, nrows=60):   \n",
    "    func_fixed = partial(func, folder=folder, train_label=train_label, event_time=event_time, nrows=nrows)     \n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(processes=multiprocessing.cpu_count()) \n",
    "        df_list = list(pool.imap(func_fixed, files)) \n",
    "        pool.close()\n",
    "        pool.join()        \n",
    "    combined_df = pd.concat(df_list)    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:42:43.480369Z",
     "start_time": "2020-02-07T05:42:43.476025Z"
    }
   },
   "outputs": [],
   "source": [
    "# train = data_loader_all_v2(data_loader_v2, train_list, folder=train_folder, train_label=train_label, \n",
    "#                            event_time=10, nrows=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:42:45.910237Z",
     "start_time": "2020-02-07T05:42:43.481596Z"
    }
   },
   "outputs": [],
   "source": [
    "train = joblib.load('data/df_train_10_60.pkl').reset_index()\n",
    "test = joblib.load('data/df_test_10.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:42:45.914322Z",
     "start_time": "2020-02-07T05:42:45.911118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5121, 'label')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cols = 'label'\n",
    "fea_cols = [c for c in train.columns if c[0] == 'V']\n",
    "len(fea_cols), y_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:43:02.525217Z",
     "start_time": "2020-02-07T05:42:45.915564Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = joblib.load('scaler_20200129T135731.bin')\n",
    "\n",
    "train[fea_cols] = scaler.transform(train[fea_cols].values)\n",
    "test[fea_cols] = scaler.transform(test[fea_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:43:02.527699Z",
     "start_time": "2020-02-07T05:43:02.526283Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=81511991154 % 2**32-1)\n",
    "\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:43:02.546002Z",
     "start_time": "2020-02-07T05:43:02.528444Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset15(Dataset):\n",
    "    def __init__(self, df, fea_cols, y_cols):        \n",
    "        self.X = df[fea_cols].values\n",
    "#         self.y = pd.get_dummies(df[y_cols]).values\n",
    "        self.y = df[y_cols].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].astype(np.float32), self.y[idx].astype(np.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:43:02.554736Z",
     "start_time": "2020-02-07T05:43:02.546773Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, criterion, optimizer, scheduler, device):\n",
    "        self.device = device\n",
    "        self.model = model#.to(self.device)\n",
    "        self.criterion = criterion#.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        print(self.model.train())\n",
    "        pass\n",
    "    \n",
    "    def train(self, data_loader, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, data in enumerate(data_loader):\n",
    "            X_batch, y_batch = data\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            \n",
    "            self.scheduler.step(epoch + i / len(data_loader))\n",
    "            self.optimizer.zero_grad()\n",
    "            y_pred = self.model(X_batch)\n",
    "#             print(y_pred, y_batch)\n",
    "            \n",
    "            loss = self.criterion(y_pred, y_batch)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        \n",
    "        return total_loss / len(data_loader)\n",
    "    \n",
    "    def eval(self, data_loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "#         print('valid_loader', len(valid_loader))\n",
    "        for data in data_loader:\n",
    "            X_batch, y_batch = data\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                y_pred = self.model(X_batch)\n",
    "                loss = self.criterion(y_pred, y_batch)\n",
    "                total_loss = total_loss + loss.item()\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "    def save(self, model_path='checkpoint.pt'):\n",
    "#         torch.save(self.model.state_dict(), 'checkpoint.pt')\n",
    "        joblib.dump(self.model, model_path)\n",
    "        return\n",
    "    \n",
    "    def load(self, model_path='checkpoint.pt'):\n",
    "#         self.model.load_state_dict(torch.load(model_path))\n",
    "        self.model = joblib.load(model_path)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:43:02.567830Z",
     "start_time": "2020-02-07T05:43:02.556321Z"
    }
   },
   "outputs": [],
   "source": [
    "class DNNModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, dropout_probability=0.3):\n",
    "        super(DNNModel,self).__init__()\n",
    "        act = torch.nn.ELU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 2048), torch.nn.BatchNorm1d(2048), act, dropout, \n",
    "            torch.nn.Linear(2048, 2048), torch.nn.BatchNorm1d(2048), act, dropout, \n",
    "            torch.nn.Linear(2048, 2048), torch.nn.BatchNorm1d(2048), act, dropout, \n",
    "            torch.nn.Linear(2048, 2048), torch.nn.BatchNorm1d(2048), act, dropout, \n",
    "            torch.nn.Linear(2048, 2048), torch.nn.BatchNorm1d(2048), act, dropout, \n",
    "            torch.nn.Linear(2048, 2048), torch.nn.BatchNorm1d(2048), act, dropout, \n",
    "            torch.nn.Linear(2048, 1024), torch.nn.BatchNorm1d(1024), act, dropout,\n",
    "            torch.nn.Linear(1024, 1024), torch.nn.BatchNorm1d(1024), act, dropout, \n",
    "            torch.nn.Linear(1024, 1024), torch.nn.BatchNorm1d(1024), act, dropout, \n",
    "            torch.nn.Linear(1024, 1024), torch.nn.BatchNorm1d(1024), act, dropout, \n",
    "            torch.nn.Linear(1024, 1024), torch.nn.BatchNorm1d(1024), act, dropout, \n",
    "            torch.nn.Linear(1024, 1024), torch.nn.BatchNorm1d(1024), act, dropout, \n",
    "            torch.nn.Linear(1024, 198)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:43:02.578941Z",
     "start_time": "2020-02-07T05:43:02.569029Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    def __init__(self, dropout_probability=0.5):\n",
    "        super().__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(1, 2, 3, stride=1, padding=1), torch.nn.BatchNorm1d(2), relu,\n",
    "            torch.nn.Conv1d(2, 4, 3, stride=1, padding=1), torch.nn.BatchNorm1d(4), relu,\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.Conv1d(4, 4, 3, stride=1, padding=1), torch.nn.BatchNorm1d(4), relu,\n",
    "            torch.nn.Conv1d(4, 8, 3, stride=1, padding=1), torch.nn.BatchNorm1d(8), relu,\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.Conv1d(8, 8, 3, stride=1, padding=1), torch.nn.BatchNorm1d(8), relu,\n",
    "            torch.nn.Conv1d(8, 8, 3, stride=1, padding=1), torch.nn.BatchNorm1d(8), relu,\n",
    "            torch.nn.MaxPool1d(2),\n",
    "#             torch.nn.Conv1d(48, 96, 3, stride=1, padding=1), torch.nn.BatchNorm1d(96), relu,\n",
    "#             torch.nn.Conv1d(96, 96, 3, stride=1, padding=1), torch.nn.BatchNorm1d(96), relu,\n",
    "#             torch.nn.MaxPool1d(2),\n",
    "#             torch.nn.Conv1d(96, 96, 3, stride=1, padding=1), torch.nn.BatchNorm1d(96), relu,\n",
    "#             torch.nn.Conv1d(96, 96, 3, stride=1, padding=1), torch.nn.BatchNorm1d(96), relu,\n",
    "#             torch.nn.MaxPool1d(2),\n",
    "        )\n",
    "            \n",
    "        self.clf = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5120, 3000), torch.nn.BatchNorm1d(3000), relu, dropout,\n",
    "            torch.nn.Linear(3000, 1024), torch.nn.BatchNorm1d(1024), relu, dropout,\n",
    "            torch.nn.Linear(1024, 198)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out = self.cnn(x)\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]: #24, 4, 4\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.clf(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:48:50.269969Z",
     "start_time": "2020-02-07T07:48:50.259539Z"
    }
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size, output_size=128):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 2048), torch.nn.BatchNorm1d(2048),#nn.ReLU(True),\n",
    "            nn.Linear(2048, 2048), torch.nn.BatchNorm1d(2048),#nn.ReLU(True), \n",
    "            nn.Linear(2048, 2048), torch.nn.BatchNorm1d(2048),#nn.ReLU(True), \n",
    "            nn.Linear(2048, 1024), torch.nn.BatchNorm1d(1024),#nn.ReLU(True), \n",
    "            nn.Linear(1024, 512), torch.nn.BatchNorm1d(512),#nn.ReLU(True), \n",
    "            nn.Linear(512, 256), torch.nn.BatchNorm1d(256),#nn.ReLU(True), \n",
    "            nn.Linear(256, output_size), nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_size, 256), torch.nn.BatchNorm1d(256),#nn.ReLU(True),\n",
    "            nn.Linear(256, 512), torch.nn.BatchNorm1d(512),#nn.ReLU(True),\n",
    "            nn.Linear(512, 1024), torch.nn.BatchNorm1d(1024),#nn.ReLU(True), \n",
    "            nn.Linear(1024, 2048), torch.nn.BatchNorm1d(2048),#nn.ReLU(True), \n",
    "            nn.Linear(2048, 2048), torch.nn.BatchNorm1d(2048),#nn.ReLU(True), \n",
    "            nn.Linear(2048, 2048), torch.nn.BatchNorm1d(2048),#nn.ReLU(True), \n",
    "            nn.Linear(2048, input_size), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:48:50.623687Z",
     "start_time": "2020-02-07T07:48:50.619135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200207T164850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81511991154"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "print(model_ts)\n",
    "\n",
    "# print(f'fea_size {len(fea_cols)} layer_cols {layer_cols}')\n",
    "\n",
    "torch.manual_seed(81511991154)\n",
    "torch.initial_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:48:51.306269Z",
     "start_time": "2020-02-07T07:48:50.802753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33120 8280\n",
      "batch_size 3000 num_workers 8\n",
      "train_loader 12 val_loader 1\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset15(train[fea_cols + [y_cols]], fea_cols, y_cols)\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [int(train.shape[0] * 0.8), int(train.shape[0] * 0.2)])\n",
    "\n",
    "print(len(train_set), len(val_set))\n",
    "\n",
    "batch_size = 3000\n",
    "num_workers = 8\n",
    "\n",
    "all_loader = DataLoader(dataset=dataset, batch_size=len(dataset) // 2, num_workers=num_workers, shuffle=True)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=len(val_set))\n",
    "\n",
    "print(f'batch_size {batch_size} num_workers {num_workers}')\n",
    "print(f'train_loader {len(train_loader)} val_loader {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T09:30:36.936125Z",
     "start_time": "2020-02-07T09:14:06.865337Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74b5a73b5b844bd96dd79b74de742ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=400, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200207T181409] Epock 0 / 400\t lr 0.005\n",
      "  train_loss: 0.0038892246084287763\n",
      "Validation loss decreased (inf --> 0.00388922).  Saving model ...\n",
      "[20200207T181412] Epock 1 / 400\t lr 0.005\n",
      "  train_loss: 0.004224805044941604\n",
      "EarlyStopping 2 / 1 counter: 1 out of 500\n",
      "[20200207T181414] Epock 2 / 400\t lr 0.005\n",
      "  train_loss: 0.004126828862354159\n",
      "EarlyStopping 3 / 1 counter: 2 out of 500\n",
      "[20200207T181417] Epock 3 / 400\t lr 0.005\n",
      "  train_loss: 0.00396764138713479\n",
      "EarlyStopping 4 / 1 counter: 3 out of 500\n",
      "[20200207T181419] Epock 4 / 400\t lr 0.005\n",
      "  train_loss: 0.003875598544254899\n",
      "Validation loss decreased (0.00388922 --> 0.00387560).  Saving model ...\n",
      "[20200207T181422] Epock 5 / 400\t lr 0.005\n",
      "  train_loss: 0.004188551218248904\n",
      "EarlyStopping 6 / 1 counter: 1 out of 500\n",
      "[20200207T181424] Epock 6 / 400\t lr 0.005\n",
      "  train_loss: 0.003775612683966756\n",
      "Validation loss decreased (0.00387560 --> 0.00377561).  Saving model ...\n",
      "[20200207T181427] Epock 7 / 400\t lr 0.005\n",
      "  train_loss: 0.0039007837185636163\n",
      "EarlyStopping 8 / 1 counter: 1 out of 500\n",
      "[20200207T181429] Epock 8 / 400\t lr 0.005\n",
      "  train_loss: 0.0038634458323940635\n",
      "EarlyStopping 9 / 1 counter: 2 out of 500\n",
      "[20200207T181432] Epock 9 / 400\t lr 0.005\n",
      "  train_loss: 0.0037085303338244557\n",
      "Validation loss decreased (0.00377561 --> 0.00370853).  Saving model ...\n",
      "[20200207T181435] Epock 10 / 400\t lr 0.005\n",
      "  train_loss: 0.0037101266207173467\n",
      "EarlyStopping 11 / 1 counter: 1 out of 500\n",
      "[20200207T181437] Epock 11 / 400\t lr 0.005\n",
      "  train_loss: 0.0037807305343449116\n",
      "EarlyStopping 12 / 1 counter: 2 out of 500\n",
      "[20200207T181439] Epock 12 / 400\t lr 0.005\n",
      "  train_loss: 0.0037565313978120685\n",
      "EarlyStopping 13 / 1 counter: 3 out of 500\n",
      "[20200207T181442] Epock 13 / 400\t lr 0.005\n",
      "  train_loss: 0.003853950649499893\n",
      "EarlyStopping 14 / 1 counter: 4 out of 500\n",
      "[20200207T181444] Epock 14 / 400\t lr 0.005\n",
      "  train_loss: 0.00372637459076941\n",
      "EarlyStopping 15 / 1 counter: 5 out of 500\n",
      "[20200207T181446] Epock 15 / 400\t lr 0.005\n",
      "  train_loss: 0.0036810869351029396\n",
      "Validation loss decreased (0.00370853 --> 0.00368109).  Saving model ...\n",
      "[20200207T181449] Epock 16 / 400\t lr 0.005\n",
      "  train_loss: 0.003668472170829773\n",
      "Validation loss decreased (0.00368109 --> 0.00366847).  Saving model ...\n",
      "[20200207T181452] Epock 17 / 400\t lr 0.005\n",
      "  train_loss: 0.0037481292383745313\n",
      "EarlyStopping 18 / 1 counter: 1 out of 500\n",
      "[20200207T181454] Epock 18 / 400\t lr 0.005\n",
      "  train_loss: 0.003624596749432385\n",
      "Validation loss decreased (0.00366847 --> 0.00362460).  Saving model ...\n",
      "[20200207T181457] Epock 19 / 400\t lr 0.005\n",
      "  train_loss: 0.0036311568692326546\n",
      "EarlyStopping 20 / 1 counter: 1 out of 500\n",
      "[20200207T181459] Epock 20 / 400\t lr 0.005\n",
      "  train_loss: 0.003625611658208072\n",
      "EarlyStopping 21 / 1 counter: 2 out of 500\n",
      "[20200207T181502] Epock 21 / 400\t lr 0.005\n",
      "  train_loss: 0.0036126943305134773\n",
      "Validation loss decreased (0.00362460 --> 0.00361269).  Saving model ...\n",
      "[20200207T181505] Epock 22 / 400\t lr 0.005\n",
      "  train_loss: 0.0037146586691960692\n",
      "EarlyStopping 23 / 1 counter: 1 out of 500\n",
      "[20200207T181507] Epock 23 / 400\t lr 0.005\n",
      "  train_loss: 0.003655137144960463\n",
      "EarlyStopping 24 / 1 counter: 2 out of 500\n",
      "[20200207T181509] Epock 24 / 400\t lr 0.005\n",
      "  train_loss: 0.003605443285778165\n",
      "Validation loss decreased (0.00361269 --> 0.00360544).  Saving model ...\n",
      "[20200207T181512] Epock 25 / 400\t lr 0.005\n",
      "  train_loss: 0.0037389377830550075\n",
      "EarlyStopping 26 / 1 counter: 1 out of 500\n",
      "[20200207T181515] Epock 26 / 400\t lr 0.005\n",
      "  train_loss: 0.003740291460417211\n",
      "EarlyStopping 27 / 1 counter: 2 out of 500\n",
      "[20200207T181517] Epock 27 / 400\t lr 0.005\n",
      "  train_loss: 0.003672076272778213\n",
      "EarlyStopping 28 / 1 counter: 3 out of 500\n",
      "[20200207T181519] Epock 28 / 400\t lr 0.005\n",
      "  train_loss: 0.0036028565373271704\n",
      "Validation loss decreased (0.00360544 --> 0.00360286).  Saving model ...\n",
      "[20200207T181522] Epock 29 / 400\t lr 0.005\n",
      "  train_loss: 0.003663336276076734\n",
      "EarlyStopping 30 / 1 counter: 1 out of 500\n",
      "[20200207T181525] Epock 30 / 400\t lr 0.005\n",
      "  train_loss: 0.003610834595747292\n",
      "EarlyStopping 31 / 1 counter: 2 out of 500\n",
      "[20200207T181527] Epock 31 / 400\t lr 0.005\n",
      "  train_loss: 0.0036238249158486724\n",
      "EarlyStopping 32 / 1 counter: 3 out of 500\n",
      "[20200207T181529] Epock 32 / 400\t lr 0.005\n",
      "  train_loss: 0.00374365272000432\n",
      "EarlyStopping 33 / 1 counter: 4 out of 500\n",
      "[20200207T181532] Epock 33 / 400\t lr 0.005\n",
      "  train_loss: 0.00362691015470773\n",
      "EarlyStopping 34 / 1 counter: 5 out of 500\n",
      "[20200207T181534] Epock 34 / 400\t lr 0.005\n",
      "  train_loss: 0.003671150654554367\n",
      "EarlyStopping 35 / 1 counter: 6 out of 500\n",
      "[20200207T181536] Epock 35 / 400\t lr 0.005\n",
      "  train_loss: 0.003679311601445079\n",
      "EarlyStopping 36 / 1 counter: 7 out of 500\n",
      "[20200207T181539] Epock 36 / 400\t lr 0.005\n",
      "  train_loss: 0.0037965073715895414\n",
      "EarlyStopping 37 / 1 counter: 8 out of 500\n",
      "[20200207T181541] Epock 37 / 400\t lr 0.005\n",
      "  train_loss: 0.0037001273594796658\n",
      "EarlyStopping 38 / 1 counter: 9 out of 500\n",
      "[20200207T181543] Epock 38 / 400\t lr 0.005\n",
      "  train_loss: 0.003691411577165127\n",
      "EarlyStopping 39 / 1 counter: 10 out of 500\n",
      "[20200207T181546] Epock 39 / 400\t lr 0.005\n",
      "  train_loss: 0.0036109548527747393\n",
      "EarlyStopping 40 / 1 counter: 11 out of 500\n",
      "[20200207T181548] Epock 40 / 400\t lr 0.005\n",
      "  train_loss: 0.003688337281346321\n",
      "EarlyStopping 41 / 1 counter: 12 out of 500\n",
      "[20200207T181550] Epock 41 / 400\t lr 0.005\n",
      "  train_loss: 0.003601480391807854\n",
      "Validation loss decreased (0.00360286 --> 0.00360148).  Saving model ...\n",
      "[20200207T181553] Epock 42 / 400\t lr 0.005\n",
      "  train_loss: 0.0035975370556116104\n",
      "Validation loss decreased (0.00360148 --> 0.00359754).  Saving model ...\n",
      "[20200207T181556] Epock 43 / 400\t lr 0.005\n",
      "  train_loss: 0.0036720947828143835\n",
      "EarlyStopping 44 / 1 counter: 1 out of 500\n",
      "[20200207T181559] Epock 44 / 400\t lr 0.005\n",
      "  train_loss: 0.0036479447735473514\n",
      "EarlyStopping 45 / 1 counter: 2 out of 500\n",
      "[20200207T181601] Epock 45 / 400\t lr 0.005\n",
      "  train_loss: 0.0036804662086069584\n",
      "EarlyStopping 46 / 1 counter: 3 out of 500\n",
      "[20200207T181603] Epock 46 / 400\t lr 0.005\n",
      "  train_loss: 0.003597590490244329\n",
      "EarlyStopping 47 / 1 counter: 4 out of 500\n",
      "[20200207T181606] Epock 47 / 400\t lr 0.005\n",
      "  train_loss: 0.0036349374568089843\n",
      "EarlyStopping 48 / 1 counter: 5 out of 500\n",
      "[20200207T181608] Epock 48 / 400\t lr 0.005\n",
      "  train_loss: 0.0035607864847406745\n",
      "Validation loss decreased (0.00359754 --> 0.00356079).  Saving model ...\n",
      "[20200207T181611] Epock 49 / 400\t lr 0.0025\n",
      "  train_loss: 0.003627343336120248\n",
      "EarlyStopping 50 / 1 counter: 1 out of 500\n",
      "[20200207T181613] Epock 50 / 400\t lr 0.0025\n",
      "  train_loss: 0.0036661456106230617\n",
      "EarlyStopping 51 / 1 counter: 2 out of 500\n",
      "[20200207T181616] Epock 51 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035524722188711166\n",
      "Validation loss decreased (0.00356079 --> 0.00355247).  Saving model ...\n",
      "[20200207T181618] Epock 52 / 400\t lr 0.0025\n",
      "  train_loss: 0.0036706009414047003\n",
      "EarlyStopping 53 / 1 counter: 1 out of 500\n",
      "[20200207T181621] Epock 53 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035999921383336186\n",
      "EarlyStopping 54 / 1 counter: 2 out of 500\n",
      "[20200207T181623] Epock 54 / 400\t lr 0.0025\n",
      "  train_loss: 0.0036136567359790206\n",
      "EarlyStopping 55 / 1 counter: 3 out of 500\n",
      "[20200207T181625] Epock 55 / 400\t lr 0.0025\n",
      "  train_loss: 0.003637450048699975\n",
      "EarlyStopping 56 / 1 counter: 4 out of 500\n",
      "[20200207T181628] Epock 56 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035336281871423125\n",
      "Validation loss decreased (0.00355247 --> 0.00353363).  Saving model ...\n",
      "[20200207T181631] Epock 57 / 400\t lr 0.0025\n",
      "  train_loss: 0.003557016374543309\n",
      "EarlyStopping 58 / 1 counter: 1 out of 500\n",
      "[20200207T181633] Epock 58 / 400\t lr 0.0025\n",
      "  train_loss: 0.003531354246661067\n",
      "Validation loss decreased (0.00353363 --> 0.00353135).  Saving model ...\n",
      "[20200207T181636] Epock 59 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035614391090348363\n",
      "EarlyStopping 60 / 1 counter: 1 out of 500\n",
      "[20200207T181638] Epock 60 / 400\t lr 0.0025\n",
      "  train_loss: 0.003517444129101932\n",
      "Validation loss decreased (0.00353135 --> 0.00351744).  Saving model ...\n",
      "[20200207T181641] Epock 61 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035095044877380133\n",
      "Validation loss decreased (0.00351744 --> 0.00350950).  Saving model ...\n",
      "[20200207T181644] Epock 62 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035010812571272254\n",
      "Validation loss decreased (0.00350950 --> 0.00350108).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200207T181647] Epock 63 / 400\t lr 0.0025\n",
      "  train_loss: 0.003507172572426498\n",
      "EarlyStopping 64 / 1 counter: 1 out of 500\n",
      "[20200207T181649] Epock 64 / 400\t lr 0.0025\n",
      "  train_loss: 0.003529568202793598\n",
      "EarlyStopping 65 / 1 counter: 2 out of 500\n",
      "[20200207T181652] Epock 65 / 400\t lr 0.0025\n",
      "  train_loss: 0.0036226403899490833\n",
      "EarlyStopping 66 / 1 counter: 3 out of 500\n",
      "[20200207T181654] Epock 66 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035024541430175304\n",
      "EarlyStopping 67 / 1 counter: 4 out of 500\n",
      "[20200207T181656] Epock 67 / 400\t lr 0.0025\n",
      "  train_loss: 0.003553695511072874\n",
      "EarlyStopping 68 / 1 counter: 5 out of 500\n",
      "[20200207T181659] Epock 68 / 400\t lr 0.0025\n",
      "  train_loss: 0.0034875894198194146\n",
      "Validation loss decreased (0.00350108 --> 0.00348759).  Saving model ...\n",
      "[20200207T181702] Epock 69 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035308286314830184\n",
      "EarlyStopping 70 / 1 counter: 1 out of 500\n",
      "[20200207T181704] Epock 70 / 400\t lr 0.0025\n",
      "  train_loss: 0.003488015732727945\n",
      "EarlyStopping 71 / 1 counter: 2 out of 500\n",
      "[20200207T181706] Epock 71 / 400\t lr 0.0025\n",
      "  train_loss: 0.003478602971881628\n",
      "Validation loss decreased (0.00348759 --> 0.00347860).  Saving model ...\n",
      "[20200207T181709] Epock 72 / 400\t lr 0.0025\n",
      "  train_loss: 0.003486993140541017\n",
      "EarlyStopping 73 / 1 counter: 1 out of 500\n",
      "[20200207T181711] Epock 73 / 400\t lr 0.0025\n",
      "  train_loss: 0.0034649913432076573\n",
      "Validation loss decreased (0.00347860 --> 0.00346499).  Saving model ...\n",
      "[20200207T181714] Epock 74 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035381458001211286\n",
      "EarlyStopping 75 / 1 counter: 1 out of 500\n",
      "[20200207T181717] Epock 75 / 400\t lr 0.0025\n",
      "  train_loss: 0.00346900534350425\n",
      "EarlyStopping 76 / 1 counter: 2 out of 500\n",
      "[20200207T181719] Epock 76 / 400\t lr 0.0025\n",
      "  train_loss: 0.0034666910069063306\n",
      "EarlyStopping 77 / 1 counter: 3 out of 500\n",
      "[20200207T181721] Epock 77 / 400\t lr 0.0025\n",
      "  train_loss: 0.0034744534641504288\n",
      "EarlyStopping 78 / 1 counter: 4 out of 500\n",
      "[20200207T181724] Epock 78 / 400\t lr 0.0025\n",
      "  train_loss: 0.003539822530001402\n",
      "EarlyStopping 79 / 1 counter: 5 out of 500\n",
      "[20200207T181726] Epock 79 / 400\t lr 0.0025\n",
      "  train_loss: 0.003672185819596052\n",
      "EarlyStopping 80 / 1 counter: 6 out of 500\n",
      "[20200207T181728] Epock 80 / 400\t lr 0.0025\n",
      "  train_loss: 0.0036053932271897793\n",
      "EarlyStopping 81 / 1 counter: 7 out of 500\n",
      "[20200207T181731] Epock 81 / 400\t lr 0.0025\n",
      "  train_loss: 0.0034678023075684905\n",
      "EarlyStopping 82 / 1 counter: 8 out of 500\n",
      "[20200207T181733] Epock 82 / 400\t lr 0.0025\n",
      "  train_loss: 0.003487632842734456\n",
      "EarlyStopping 83 / 1 counter: 9 out of 500\n",
      "[20200207T181735] Epock 83 / 400\t lr 0.0025\n",
      "  train_loss: 0.003589891828596592\n",
      "EarlyStopping 84 / 1 counter: 10 out of 500\n",
      "[20200207T181738] Epock 84 / 400\t lr 0.0025\n",
      "  train_loss: 0.003435280406847596\n",
      "Validation loss decreased (0.00346499 --> 0.00343528).  Saving model ...\n",
      "[20200207T181741] Epock 85 / 400\t lr 0.0025\n",
      "  train_loss: 0.003544183913618326\n",
      "EarlyStopping 86 / 1 counter: 1 out of 500\n",
      "[20200207T181743] Epock 86 / 400\t lr 0.0025\n",
      "  train_loss: 0.0034542230423539877\n",
      "EarlyStopping 87 / 1 counter: 2 out of 500\n",
      "[20200207T181745] Epock 87 / 400\t lr 0.0025\n",
      "  train_loss: 0.0034281566040590405\n",
      "Validation loss decreased (0.00343528 --> 0.00342816).  Saving model ...\n",
      "[20200207T181748] Epock 88 / 400\t lr 0.0025\n",
      "  train_loss: 0.003428175114095211\n",
      "EarlyStopping 89 / 1 counter: 1 out of 500\n",
      "[20200207T181751] Epock 89 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035606990568339825\n",
      "EarlyStopping 90 / 1 counter: 2 out of 500\n",
      "[20200207T181753] Epock 90 / 400\t lr 0.0025\n",
      "  train_loss: 0.0034191982122138143\n",
      "Validation loss decreased (0.00342816 --> 0.00341920).  Saving model ...\n",
      "[20200207T181756] Epock 91 / 400\t lr 0.0025\n",
      "  train_loss: 0.003421788802370429\n",
      "EarlyStopping 92 / 1 counter: 1 out of 500\n",
      "[20200207T181758] Epock 92 / 400\t lr 0.0025\n",
      "  train_loss: 0.0035396047169342637\n",
      "EarlyStopping 93 / 1 counter: 2 out of 500\n",
      "[20200207T181800] Epock 93 / 400\t lr 0.0025\n",
      "  train_loss: 0.003401434631086886\n",
      "Validation loss decreased (0.00341920 --> 0.00340143).  Saving model ...\n",
      "[20200207T181803] Epock 94 / 400\t lr 0.0025\n",
      "  train_loss: 0.003405172727070749\n",
      "EarlyStopping 95 / 1 counter: 1 out of 500\n",
      "[20200207T181806] Epock 95 / 400\t lr 0.0025\n",
      "  train_loss: 0.0033952088560909033\n",
      "Validation loss decreased (0.00340143 --> 0.00339521).  Saving model ...\n",
      "[20200207T181809] Epock 96 / 400\t lr 0.0025\n",
      "  train_loss: 0.0034011718817055225\n",
      "EarlyStopping 97 / 1 counter: 1 out of 500\n",
      "[20200207T181811] Epock 97 / 400\t lr 0.0025\n",
      "  train_loss: 0.0033873930806294084\n",
      "Validation loss decreased (0.00339521 --> 0.00338739).  Saving model ...\n",
      "[20200207T181814] Epock 98 / 400\t lr 0.0025\n",
      "  train_loss: 0.003389781340956688\n",
      "EarlyStopping 99 / 1 counter: 1 out of 500\n",
      "[20200207T181816] Epock 99 / 400\t lr 0.00125\n",
      "  train_loss: 0.003385917516425252\n",
      "Validation loss decreased (0.00338739 --> 0.00338592).  Saving model ...\n",
      "[20200207T181819] Epock 100 / 400\t lr 0.00125\n",
      "  train_loss: 0.0034396129194647074\n",
      "EarlyStopping 101 / 1 counter: 1 out of 500\n",
      "[20200207T181822] Epock 101 / 400\t lr 0.00125\n",
      "  train_loss: 0.00336337520275265\n",
      "Validation loss decreased (0.00338592 --> 0.00336338).  Saving model ...\n",
      "[20200207T181824] Epock 102 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033585858764126897\n",
      "Validation loss decreased (0.00336338 --> 0.00335859).  Saving model ...\n",
      "[20200207T181827] Epock 103 / 400\t lr 0.00125\n",
      "  train_loss: 0.0034388366620987654\n",
      "EarlyStopping 104 / 1 counter: 1 out of 500\n",
      "[20200207T181830] Epock 104 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033577256835997105\n",
      "Validation loss decreased (0.00335859 --> 0.00335773).  Saving model ...\n",
      "[20200207T181832] Epock 105 / 400\t lr 0.00125\n",
      "  train_loss: 0.003462017746642232\n",
      "EarlyStopping 106 / 1 counter: 1 out of 500\n",
      "[20200207T181835] Epock 106 / 400\t lr 0.00125\n",
      "  train_loss: 0.003372912062332034\n",
      "EarlyStopping 107 / 1 counter: 2 out of 500\n",
      "[20200207T181837] Epock 107 / 400\t lr 0.00125\n",
      "  train_loss: 0.003371747210621834\n",
      "EarlyStopping 108 / 1 counter: 3 out of 500\n",
      "[20200207T181839] Epock 108 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033589539816603065\n",
      "EarlyStopping 109 / 1 counter: 4 out of 500\n",
      "[20200207T181842] Epock 109 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033910336205735803\n",
      "EarlyStopping 110 / 1 counter: 5 out of 500\n",
      "[20200207T181844] Epock 110 / 400\t lr 0.00125\n",
      "  train_loss: 0.0034588369308039546\n",
      "EarlyStopping 111 / 1 counter: 6 out of 500\n",
      "[20200207T181846] Epock 111 / 400\t lr 0.00125\n",
      "  train_loss: 0.003353588981553912\n",
      "Validation loss decreased (0.00335773 --> 0.00335359).  Saving model ...\n",
      "[20200207T181849] Epock 112 / 400\t lr 0.00125\n",
      "  train_loss: 0.003348341677337885\n",
      "Validation loss decreased (0.00335359 --> 0.00334834).  Saving model ...\n",
      "[20200207T181852] Epock 113 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033423068234696984\n",
      "Validation loss decreased (0.00334834 --> 0.00334231).  Saving model ...\n",
      "[20200207T181855] Epock 114 / 400\t lr 0.00125\n",
      "  train_loss: 0.003338775713928044\n",
      "Validation loss decreased (0.00334231 --> 0.00333878).  Saving model ...\n",
      "[20200207T181858] Epock 115 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033316450426355004\n",
      "Validation loss decreased (0.00333878 --> 0.00333165).  Saving model ...\n",
      "[20200207T181901] Epock 116 / 400\t lr 0.00125\n",
      "  train_loss: 0.003489093855023384\n",
      "EarlyStopping 117 / 1 counter: 1 out of 500\n",
      "[20200207T181903] Epock 117 / 400\t lr 0.00125\n",
      "  train_loss: 0.0035119616659358144\n",
      "EarlyStopping 118 / 1 counter: 2 out of 500\n",
      "[20200207T181906] Epock 118 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033388080773875117\n",
      "EarlyStopping 119 / 1 counter: 3 out of 500\n",
      "[20200207T181908] Epock 119 / 400\t lr 0.00125\n",
      "  train_loss: 0.003495607990771532\n",
      "EarlyStopping 120 / 1 counter: 4 out of 500\n",
      "[20200207T181910] Epock 120 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033295704051852226\n",
      "Validation loss decreased (0.00333165 --> 0.00332957).  Saving model ...\n",
      "[20200207T181913] Epock 121 / 400\t lr 0.00125\n",
      "  train_loss: 0.003320830292068422\n",
      "Validation loss decreased (0.00332957 --> 0.00332083).  Saving model ...\n",
      "[20200207T181916] Epock 122 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033241789788007736\n",
      "EarlyStopping 123 / 1 counter: 1 out of 500\n",
      "[20200207T181918] Epock 123 / 400\t lr 0.00125\n",
      "  train_loss: 0.003363079624250531\n",
      "EarlyStopping 124 / 1 counter: 2 out of 500\n",
      "[20200207T181921] Epock 124 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033226500963792205\n",
      "EarlyStopping 125 / 1 counter: 3 out of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200207T181923] Epock 125 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033321689115837216\n",
      "EarlyStopping 126 / 1 counter: 4 out of 500\n",
      "[20200207T181926] Epock 126 / 400\t lr 0.00125\n",
      "  train_loss: 0.003327171318233013\n",
      "EarlyStopping 127 / 1 counter: 5 out of 500\n",
      "[20200207T181928] Epock 127 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033008691389113665\n",
      "Validation loss decreased (0.00332083 --> 0.00330087).  Saving model ...\n",
      "[20200207T181931] Epock 128 / 400\t lr 0.00125\n",
      "  train_loss: 0.003311005770228803\n",
      "EarlyStopping 129 / 1 counter: 1 out of 500\n",
      "[20200207T181933] Epock 129 / 400\t lr 0.00125\n",
      "  train_loss: 0.003363437717780471\n",
      "EarlyStopping 130 / 1 counter: 2 out of 500\n",
      "[20200207T181936] Epock 130 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033672467106953263\n",
      "EarlyStopping 131 / 1 counter: 3 out of 500\n",
      "[20200207T181938] Epock 131 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033310374710708857\n",
      "EarlyStopping 132 / 1 counter: 4 out of 500\n",
      "[20200207T181940] Epock 132 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033196735894307494\n",
      "EarlyStopping 133 / 1 counter: 5 out of 500\n",
      "[20200207T181943] Epock 133 / 400\t lr 0.00125\n",
      "  train_loss: 0.003307485952973366\n",
      "EarlyStopping 134 / 1 counter: 6 out of 500\n",
      "[20200207T181945] Epock 134 / 400\t lr 0.00125\n",
      "  train_loss: 0.00330690189730376\n",
      "EarlyStopping 135 / 1 counter: 7 out of 500\n",
      "[20200207T181947] Epock 135 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033018795074895024\n",
      "EarlyStopping 136 / 1 counter: 8 out of 500\n",
      "[20200207T181950] Epock 136 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033135651610791683\n",
      "EarlyStopping 137 / 1 counter: 9 out of 500\n",
      "[20200207T181952] Epock 137 / 400\t lr 0.00125\n",
      "  train_loss: 0.003322210628539324\n",
      "EarlyStopping 138 / 1 counter: 10 out of 500\n",
      "[20200207T181954] Epock 138 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033792139729484916\n",
      "EarlyStopping 139 / 1 counter: 11 out of 500\n",
      "[20200207T181957] Epock 139 / 400\t lr 0.00125\n",
      "  train_loss: 0.003297660849057138\n",
      "Validation loss decreased (0.00330087 --> 0.00329766).  Saving model ...\n",
      "[20200207T182000] Epock 140 / 400\t lr 0.00125\n",
      "  train_loss: 0.0032949851593002677\n",
      "Validation loss decreased (0.00329766 --> 0.00329499).  Saving model ...\n",
      "[20200207T182003] Epock 141 / 400\t lr 0.00125\n",
      "  train_loss: 0.0032975318608805537\n",
      "EarlyStopping 142 / 1 counter: 1 out of 500\n",
      "[20200207T182005] Epock 142 / 400\t lr 0.00125\n",
      "  train_loss: 0.003407311625778675\n",
      "EarlyStopping 143 / 1 counter: 2 out of 500\n",
      "[20200207T182007] Epock 143 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033024041913449764\n",
      "EarlyStopping 144 / 1 counter: 3 out of 500\n",
      "[20200207T182010] Epock 144 / 400\t lr 0.00125\n",
      "  train_loss: 0.0034407167695462704\n",
      "EarlyStopping 145 / 1 counter: 4 out of 500\n",
      "[20200207T182012] Epock 145 / 400\t lr 0.00125\n",
      "  train_loss: 0.003310384461656213\n",
      "EarlyStopping 146 / 1 counter: 5 out of 500\n",
      "[20200207T182014] Epock 146 / 400\t lr 0.00125\n",
      "  train_loss: 0.003298120805993676\n",
      "EarlyStopping 147 / 1 counter: 6 out of 500\n",
      "[20200207T182017] Epock 147 / 400\t lr 0.00125\n",
      "  train_loss: 0.003290219698101282\n",
      "Validation loss decreased (0.00329499 --> 0.00329022).  Saving model ...\n",
      "[20200207T182020] Epock 148 / 400\t lr 0.00125\n",
      "  train_loss: 0.0033171653049066663\n",
      "EarlyStopping 149 / 1 counter: 1 out of 500\n",
      "[20200207T182022] Epock 149 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032797958701848984\n",
      "Validation loss decreased (0.00329022 --> 0.00327980).  Saving model ...\n",
      "[20200207T182025] Epock 150 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032839772757142782\n",
      "EarlyStopping 151 / 1 counter: 1 out of 500\n",
      "[20200207T182027] Epock 151 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032781315967440605\n",
      "Validation loss decreased (0.00327980 --> 0.00327813).  Saving model ...\n",
      "[20200207T182030] Epock 152 / 400\t lr 0.000625\n",
      "  train_loss: 0.0033316391054540873\n",
      "EarlyStopping 153 / 1 counter: 1 out of 500\n",
      "[20200207T182033] Epock 153 / 400\t lr 0.000625\n",
      "  train_loss: 0.0033503540325909853\n",
      "EarlyStopping 154 / 1 counter: 2 out of 500\n",
      "[20200207T182035] Epock 154 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032733293483033776\n",
      "Validation loss decreased (0.00327813 --> 0.00327333).  Saving model ...\n",
      "[20200207T182038] Epock 155 / 400\t lr 0.000625\n",
      "  train_loss: 0.003292086301371455\n",
      "EarlyStopping 156 / 1 counter: 1 out of 500\n",
      "[20200207T182040] Epock 156 / 400\t lr 0.000625\n",
      "  train_loss: 0.003328757709823549\n",
      "EarlyStopping 157 / 1 counter: 2 out of 500\n",
      "[20200207T182043] Epock 157 / 400\t lr 0.000625\n",
      "  train_loss: 0.003320191870443523\n",
      "EarlyStopping 158 / 1 counter: 3 out of 500\n",
      "[20200207T182045] Epock 158 / 400\t lr 0.000625\n",
      "  train_loss: 0.003269044100306928\n",
      "Validation loss decreased (0.00327333 --> 0.00326904).  Saving model ...\n",
      "[20200207T182048] Epock 159 / 400\t lr 0.000625\n",
      "  train_loss: 0.003268611035309732\n",
      "Validation loss decreased (0.00326904 --> 0.00326861).  Saving model ...\n",
      "[20200207T182051] Epock 160 / 400\t lr 0.000625\n",
      "  train_loss: 0.003288620267994702\n",
      "EarlyStopping 161 / 1 counter: 1 out of 500\n",
      "[20200207T182053] Epock 161 / 400\t lr 0.000625\n",
      "  train_loss: 0.003283495781943202\n",
      "EarlyStopping 162 / 1 counter: 2 out of 500\n",
      "[20200207T182055] Epock 162 / 400\t lr 0.000625\n",
      "  train_loss: 0.003279760596342385\n",
      "EarlyStopping 163 / 1 counter: 3 out of 500\n",
      "[20200207T182058] Epock 163 / 400\t lr 0.000625\n",
      "  train_loss: 0.003343518008477986\n",
      "EarlyStopping 164 / 1 counter: 4 out of 500\n",
      "[20200207T182100] Epock 164 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032604712760075927\n",
      "Validation loss decreased (0.00326861 --> 0.00326047).  Saving model ...\n",
      "[20200207T182103] Epock 165 / 400\t lr 0.000625\n",
      "  train_loss: 0.003324236022308469\n",
      "EarlyStopping 166 / 1 counter: 1 out of 500\n",
      "[20200207T182105] Epock 166 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032748215598985553\n",
      "EarlyStopping 167 / 1 counter: 2 out of 500\n",
      "[20200207T182107] Epock 167 / 400\t lr 0.000625\n",
      "  train_loss: 0.003265529521740973\n",
      "EarlyStopping 168 / 1 counter: 3 out of 500\n",
      "[20200207T182110] Epock 168 / 400\t lr 0.000625\n",
      "  train_loss: 0.003278890042565763\n",
      "EarlyStopping 169 / 1 counter: 4 out of 500\n",
      "[20200207T182112] Epock 169 / 400\t lr 0.000625\n",
      "  train_loss: 0.0033866552403196692\n",
      "EarlyStopping 170 / 1 counter: 5 out of 500\n",
      "[20200207T182115] Epock 170 / 400\t lr 0.000625\n",
      "  train_loss: 0.00328954856377095\n",
      "EarlyStopping 171 / 1 counter: 6 out of 500\n",
      "[20200207T182117] Epock 171 / 400\t lr 0.000625\n",
      "  train_loss: 0.003262789803557098\n",
      "EarlyStopping 172 / 1 counter: 7 out of 500\n",
      "[20200207T182119] Epock 172 / 400\t lr 0.000625\n",
      "  train_loss: 0.003263082355260849\n",
      "EarlyStopping 173 / 1 counter: 8 out of 500\n",
      "[20200207T182122] Epock 173 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032606148160994053\n",
      "EarlyStopping 174 / 1 counter: 9 out of 500\n",
      "[20200207T182124] Epock 174 / 400\t lr 0.000625\n",
      "  train_loss: 0.003257712349295616\n",
      "Validation loss decreased (0.00326047 --> 0.00325771).  Saving model ...\n",
      "[20200207T182127] Epock 175 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032617159886285663\n",
      "EarlyStopping 176 / 1 counter: 1 out of 500\n",
      "[20200207T182129] Epock 176 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032566370209679008\n",
      "Validation loss decreased (0.00325771 --> 0.00325664).  Saving model ...\n",
      "[20200207T182132] Epock 177 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032659282442182302\n",
      "EarlyStopping 178 / 1 counter: 1 out of 500\n",
      "[20200207T182134] Epock 178 / 400\t lr 0.000625\n",
      "  train_loss: 0.003271176014095545\n",
      "EarlyStopping 179 / 1 counter: 2 out of 500\n",
      "[20200207T182137] Epock 179 / 400\t lr 0.000625\n",
      "  train_loss: 0.003415570128709078\n",
      "EarlyStopping 180 / 1 counter: 3 out of 500\n",
      "[20200207T182139] Epock 180 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032512572361156344\n",
      "Validation loss decreased (0.00325664 --> 0.00325126).  Saving model ...\n",
      "[20200207T182142] Epock 181 / 400\t lr 0.000625\n",
      "  train_loss: 0.003250951529480517\n",
      "Validation loss decreased (0.00325126 --> 0.00325095).  Saving model ...\n",
      "[20200207T182145] Epock 182 / 400\t lr 0.000625\n",
      "  train_loss: 0.003260807483457029\n",
      "EarlyStopping 183 / 1 counter: 1 out of 500\n",
      "[20200207T182147] Epock 183 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032502312678843737\n",
      "Validation loss decreased (0.00325095 --> 0.00325023).  Saving model ...\n",
      "[20200207T182150] Epock 184 / 400\t lr 0.000625\n",
      "  train_loss: 0.003243106068111956\n",
      "Validation loss decreased (0.00325023 --> 0.00324311).  Saving model ...\n",
      "[20200207T182153] Epock 185 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032856386387720704\n",
      "EarlyStopping 186 / 1 counter: 1 out of 500\n",
      "[20200207T182155] Epock 186 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032552635530009866\n",
      "EarlyStopping 187 / 1 counter: 2 out of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200207T182158] Epock 187 / 400\t lr 0.000625\n",
      "  train_loss: 0.003244122606702149\n",
      "EarlyStopping 188 / 1 counter: 3 out of 500\n",
      "[20200207T182200] Epock 188 / 400\t lr 0.000625\n",
      "  train_loss: 0.003241614787839353\n",
      "Validation loss decreased (0.00324311 --> 0.00324161).  Saving model ...\n",
      "[20200207T182203] Epock 189 / 400\t lr 0.000625\n",
      "  train_loss: 0.0033032416831701994\n",
      "EarlyStopping 190 / 1 counter: 1 out of 500\n",
      "[20200207T182205] Epock 190 / 400\t lr 0.000625\n",
      "  train_loss: 0.0033230334520339966\n",
      "EarlyStopping 191 / 1 counter: 2 out of 500\n",
      "[20200207T182208] Epock 191 / 400\t lr 0.000625\n",
      "  train_loss: 0.003286878578364849\n",
      "EarlyStopping 192 / 1 counter: 3 out of 500\n",
      "[20200207T182210] Epock 192 / 400\t lr 0.000625\n",
      "  train_loss: 0.003255155519582331\n",
      "EarlyStopping 193 / 1 counter: 4 out of 500\n",
      "[20200207T182212] Epock 193 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032691163942217827\n",
      "EarlyStopping 194 / 1 counter: 5 out of 500\n",
      "[20200207T182215] Epock 194 / 400\t lr 0.000625\n",
      "  train_loss: 0.003238717676140368\n",
      "Validation loss decreased (0.00324161 --> 0.00323872).  Saving model ...\n",
      "[20200207T182218] Epock 195 / 400\t lr 0.000625\n",
      "  train_loss: 0.00323654618114233\n",
      "Validation loss decreased (0.00323872 --> 0.00323655).  Saving model ...\n",
      "[20200207T182220] Epock 196 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032377574825659394\n",
      "EarlyStopping 197 / 1 counter: 1 out of 500\n",
      "[20200207T182223] Epock 197 / 400\t lr 0.000625\n",
      "  train_loss: 0.003247736836783588\n",
      "EarlyStopping 198 / 1 counter: 2 out of 500\n",
      "[20200207T182225] Epock 198 / 400\t lr 0.000625\n",
      "  train_loss: 0.0032516964711248875\n",
      "EarlyStopping 199 / 1 counter: 3 out of 500\n",
      "[20200207T182228] Epock 199 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003236018819734454\n",
      "Validation loss decreased (0.00323655 --> 0.00323602).  Saving model ...\n",
      "[20200207T182231] Epock 200 / 400\t lr 0.0003125\n",
      "  train_loss: 0.00324171653483063\n",
      "EarlyStopping 201 / 1 counter: 1 out of 500\n",
      "[20200207T182233] Epock 201 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003227005247026682\n",
      "Validation loss decreased (0.00323602 --> 0.00322701).  Saving model ...\n",
      "[20200207T182236] Epock 202 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032290485687553883\n",
      "EarlyStopping 203 / 1 counter: 1 out of 500\n",
      "[20200207T182238] Epock 203 / 400\t lr 0.0003125\n",
      "  train_loss: 0.00323030271101743\n",
      "EarlyStopping 204 / 1 counter: 2 out of 500\n",
      "[20200207T182241] Epock 204 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003229618421755731\n",
      "EarlyStopping 205 / 1 counter: 3 out of 500\n",
      "[20200207T182243] Epock 205 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032258288701996207\n",
      "Validation loss decreased (0.00322701 --> 0.00322583).  Saving model ...\n",
      "[20200207T182246] Epock 206 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032232357189059258\n",
      "Validation loss decreased (0.00322583 --> 0.00322324).  Saving model ...\n",
      "[20200207T182249] Epock 207 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003342326730489731\n",
      "EarlyStopping 208 / 1 counter: 1 out of 500\n",
      "[20200207T182251] Epock 208 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003229941241443157\n",
      "EarlyStopping 209 / 1 counter: 2 out of 500\n",
      "[20200207T182253] Epock 209 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003236425924114883\n",
      "EarlyStopping 210 / 1 counter: 3 out of 500\n",
      "[20200207T182256] Epock 210 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032431890722364187\n",
      "EarlyStopping 211 / 1 counter: 4 out of 500\n",
      "[20200207T182258] Epock 211 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003221427439711988\n",
      "Validation loss decreased (0.00322324 --> 0.00322143).  Saving model ...\n",
      "[20200207T182301] Epock 212 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032482834067195654\n",
      "EarlyStopping 213 / 1 counter: 1 out of 500\n",
      "[20200207T182303] Epock 213 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032325441716238856\n",
      "EarlyStopping 214 / 1 counter: 2 out of 500\n",
      "[20200207T182306] Epock 214 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032213499071076512\n",
      "Validation loss decreased (0.00322143 --> 0.00322135).  Saving model ...\n",
      "[20200207T182309] Epock 215 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003253471222706139\n",
      "EarlyStopping 216 / 1 counter: 1 out of 500\n",
      "[20200207T182311] Epock 216 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003234763047657907\n",
      "EarlyStopping 217 / 1 counter: 2 out of 500\n",
      "[20200207T182313] Epock 217 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003280996694229543\n",
      "EarlyStopping 218 / 1 counter: 3 out of 500\n",
      "[20200207T182316] Epock 218 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003230496891774237\n",
      "EarlyStopping 219 / 1 counter: 4 out of 500\n",
      "[20200207T182318] Epock 219 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032307294895872474\n",
      "EarlyStopping 220 / 1 counter: 5 out of 500\n",
      "[20200207T182320] Epock 220 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032488448778167367\n",
      "EarlyStopping 221 / 1 counter: 6 out of 500\n",
      "[20200207T182323] Epock 221 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003287945408374071\n",
      "EarlyStopping 222 / 1 counter: 7 out of 500\n",
      "[20200207T182325] Epock 222 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032119604293257\n",
      "Validation loss decreased (0.00322135 --> 0.00321196).  Saving model ...\n",
      "[20200207T182328] Epock 223 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032222114969044924\n",
      "EarlyStopping 224 / 1 counter: 1 out of 500\n",
      "[20200207T182330] Epock 224 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032120043179020286\n",
      "EarlyStopping 225 / 1 counter: 2 out of 500\n",
      "[20200207T182333] Epock 225 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032148006139323115\n",
      "EarlyStopping 226 / 1 counter: 3 out of 500\n",
      "[20200207T182335] Epock 226 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032105310820043087\n",
      "Validation loss decreased (0.00321196 --> 0.00321053).  Saving model ...\n",
      "[20200207T182338] Epock 227 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032079890370368958\n",
      "Validation loss decreased (0.00321053 --> 0.00320799).  Saving model ...\n",
      "[20200207T182341] Epock 228 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003333289409056306\n",
      "EarlyStopping 229 / 1 counter: 1 out of 500\n",
      "[20200207T182343] Epock 229 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032045291736721992\n",
      "Validation loss decreased (0.00320799 --> 0.00320453).  Saving model ...\n",
      "[20200207T182346] Epock 230 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032029157737269998\n",
      "Validation loss decreased (0.00320453 --> 0.00320292).  Saving model ...\n",
      "[20200207T182349] Epock 231 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0033252077409997582\n",
      "EarlyStopping 232 / 1 counter: 1 out of 500\n",
      "[20200207T182351] Epock 232 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032842501532286406\n",
      "EarlyStopping 233 / 1 counter: 2 out of 500\n",
      "[20200207T182354] Epock 233 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032067522406578064\n",
      "EarlyStopping 234 / 1 counter: 3 out of 500\n",
      "[20200207T182356] Epock 234 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032083039404824376\n",
      "EarlyStopping 235 / 1 counter: 4 out of 500\n",
      "[20200207T182359] Epock 235 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003217615419998765\n",
      "EarlyStopping 236 / 1 counter: 5 out of 500\n",
      "[20200207T182401] Epock 236 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003230965929105878\n",
      "EarlyStopping 237 / 1 counter: 6 out of 500\n",
      "[20200207T182403] Epock 237 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0031997463665902615\n",
      "Validation loss decreased (0.00320292 --> 0.00319975).  Saving model ...\n",
      "[20200207T182406] Epock 238 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003200784674845636\n",
      "EarlyStopping 239 / 1 counter: 1 out of 500\n",
      "[20200207T182408] Epock 239 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003223797888495028\n",
      "EarlyStopping 240 / 1 counter: 2 out of 500\n",
      "[20200207T182411] Epock 240 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003212178940884769\n",
      "EarlyStopping 241 / 1 counter: 3 out of 500\n",
      "[20200207T182413] Epock 241 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003273561247624457\n",
      "EarlyStopping 242 / 1 counter: 4 out of 500\n",
      "[20200207T182416] Epock 242 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003199594793841243\n",
      "Validation loss decreased (0.00319975 --> 0.00319959).  Saving model ...\n",
      "[20200207T182419] Epock 243 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032069423468783498\n",
      "EarlyStopping 244 / 1 counter: 1 out of 500\n",
      "[20200207T182421] Epock 244 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032626966712996364\n",
      "EarlyStopping 245 / 1 counter: 2 out of 500\n",
      "[20200207T182423] Epock 245 / 400\t lr 0.0003125\n",
      "  train_loss: 0.003199375933036208\n",
      "Validation loss decreased (0.00319959 --> 0.00319938).  Saving model ...\n",
      "[20200207T182426] Epock 246 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0032659571152180433\n",
      "EarlyStopping 247 / 1 counter: 1 out of 500\n",
      "[20200207T182429] Epock 247 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0031997576588764787\n",
      "EarlyStopping 248 / 1 counter: 2 out of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200207T182431] Epock 248 / 400\t lr 0.0003125\n",
      "  train_loss: 0.0033088981872424483\n",
      "EarlyStopping 249 / 1 counter: 3 out of 500\n",
      "[20200207T182433] Epock 249 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032469446305185556\n",
      "EarlyStopping 250 / 1 counter: 4 out of 500\n",
      "[20200207T182436] Epock 250 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032103584380820394\n",
      "EarlyStopping 251 / 1 counter: 5 out of 500\n",
      "[20200207T182438] Epock 251 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032208506017923355\n",
      "EarlyStopping 252 / 1 counter: 6 out of 500\n",
      "[20200207T182440] Epock 252 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032436749897897243\n",
      "EarlyStopping 253 / 1 counter: 7 out of 500\n",
      "[20200207T182443] Epock 253 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032360790064558387\n",
      "EarlyStopping 254 / 1 counter: 8 out of 500\n",
      "[20200207T182445] Epock 254 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003209805116057396\n",
      "EarlyStopping 255 / 1 counter: 9 out of 500\n",
      "[20200207T182447] Epock 255 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003200023085810244\n",
      "EarlyStopping 256 / 1 counter: 10 out of 500\n",
      "[20200207T182450] Epock 256 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003205932560376823\n",
      "EarlyStopping 257 / 1 counter: 11 out of 500\n",
      "[20200207T182452] Epock 257 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003198098042048514\n",
      "Validation loss decreased (0.00319938 --> 0.00319810).  Saving model ...\n",
      "[20200207T182455] Epock 258 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003198602586053312\n",
      "EarlyStopping 259 / 1 counter: 1 out of 500\n",
      "[20200207T182457] Epock 259 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003221699735149741\n",
      "EarlyStopping 260 / 1 counter: 2 out of 500\n",
      "[20200207T182500] Epock 260 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003235955722630024\n",
      "EarlyStopping 261 / 1 counter: 3 out of 500\n",
      "[20200207T182502] Epock 261 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032180141424760222\n",
      "EarlyStopping 262 / 1 counter: 4 out of 500\n",
      "[20200207T182504] Epock 262 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032008785055950284\n",
      "EarlyStopping 263 / 1 counter: 5 out of 500\n",
      "[20200207T182507] Epock 263 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0031987751135602593\n",
      "EarlyStopping 264 / 1 counter: 6 out of 500\n",
      "[20200207T182509] Epock 264 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003201059647835791\n",
      "EarlyStopping 265 / 1 counter: 7 out of 500\n",
      "[20200207T182511] Epock 265 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003192574833519757\n",
      "Validation loss decreased (0.00319810 --> 0.00319257).  Saving model ...\n",
      "[20200207T182514] Epock 266 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003211222472600639\n",
      "EarlyStopping 267 / 1 counter: 1 out of 500\n",
      "[20200207T182517] Epock 267 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032743492629379034\n",
      "EarlyStopping 268 / 1 counter: 2 out of 500\n",
      "[20200207T182519] Epock 268 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0031974964076653123\n",
      "EarlyStopping 269 / 1 counter: 3 out of 500\n",
      "[20200207T182521] Epock 269 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0031926395604386926\n",
      "EarlyStopping 270 / 1 counter: 4 out of 500\n",
      "[20200207T182524] Epock 270 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003200858016498387\n",
      "EarlyStopping 271 / 1 counter: 5 out of 500\n",
      "[20200207T182526] Epock 271 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003204558859579265\n",
      "EarlyStopping 272 / 1 counter: 6 out of 500\n",
      "[20200207T182528] Epock 272 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032033969182521105\n",
      "EarlyStopping 273 / 1 counter: 7 out of 500\n",
      "[20200207T182531] Epock 273 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003199155442416668\n",
      "EarlyStopping 274 / 1 counter: 8 out of 500\n",
      "[20200207T182533] Epock 274 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003192420001141727\n",
      "Validation loss decreased (0.00319257 --> 0.00319242).  Saving model ...\n",
      "[20200207T182536] Epock 275 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003278651158325374\n",
      "EarlyStopping 276 / 1 counter: 1 out of 500\n",
      "[20200207T182538] Epock 276 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032081129029393196\n",
      "EarlyStopping 277 / 1 counter: 2 out of 500\n",
      "[20200207T182541] Epock 277 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032010572031140327\n",
      "EarlyStopping 278 / 1 counter: 3 out of 500\n",
      "[20200207T182543] Epock 278 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032003591768443584\n",
      "EarlyStopping 279 / 1 counter: 4 out of 500\n",
      "[20200207T182545] Epock 279 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003210372873581946\n",
      "EarlyStopping 280 / 1 counter: 5 out of 500\n",
      "[20200207T182548] Epock 280 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003195997327566147\n",
      "EarlyStopping 281 / 1 counter: 6 out of 500\n",
      "[20200207T182550] Epock 281 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003345560049638152\n",
      "EarlyStopping 282 / 1 counter: 7 out of 500\n",
      "[20200207T182552] Epock 282 / 400\t lr 0.00015625\n",
      "  train_loss: 0.00319269101601094\n",
      "EarlyStopping 283 / 1 counter: 8 out of 500\n",
      "[20200207T182555] Epock 283 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0031923253554850817\n",
      "Validation loss decreased (0.00319242 --> 0.00319233).  Saving model ...\n",
      "[20200207T182558] Epock 284 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032004417153075337\n",
      "EarlyStopping 285 / 1 counter: 1 out of 500\n",
      "[20200207T182600] Epock 285 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003236982272937894\n",
      "EarlyStopping 286 / 1 counter: 2 out of 500\n",
      "[20200207T182602] Epock 286 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003212957759387791\n",
      "EarlyStopping 287 / 1 counter: 3 out of 500\n",
      "[20200207T182605] Epock 287 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003218737314455211\n",
      "EarlyStopping 288 / 1 counter: 4 out of 500\n",
      "[20200207T182607] Epock 288 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0031921949703246355\n",
      "Validation loss decreased (0.00319233 --> 0.00319219).  Saving model ...\n",
      "[20200207T182610] Epock 289 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003193029551766813\n",
      "EarlyStopping 290 / 1 counter: 1 out of 500\n",
      "[20200207T182612] Epock 290 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003193645505234599\n",
      "EarlyStopping 291 / 1 counter: 2 out of 500\n",
      "[20200207T182615] Epock 291 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003233764204196632\n",
      "EarlyStopping 292 / 1 counter: 3 out of 500\n",
      "[20200207T182617] Epock 292 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032412117579951882\n",
      "EarlyStopping 293 / 1 counter: 4 out of 500\n",
      "[20200207T182619] Epock 293 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003221423365175724\n",
      "EarlyStopping 294 / 1 counter: 5 out of 500\n",
      "[20200207T182622] Epock 294 / 400\t lr 0.00015625\n",
      "  train_loss: 0.003231953247450292\n",
      "EarlyStopping 295 / 1 counter: 6 out of 500\n",
      "[20200207T182624] Epock 295 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032262775348499417\n",
      "EarlyStopping 296 / 1 counter: 7 out of 500\n",
      "[20200207T182626] Epock 296 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0031948809046298265\n",
      "EarlyStopping 297 / 1 counter: 8 out of 500\n",
      "[20200207T182629] Epock 297 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0032338371966034174\n",
      "EarlyStopping 298 / 1 counter: 9 out of 500\n",
      "[20200207T182631] Epock 298 / 400\t lr 0.00015625\n",
      "  train_loss: 0.0031897532753646374\n",
      "Validation loss decreased (0.00319219 --> 0.00318975).  Saving model ...\n",
      "[20200207T182634] Epock 299 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003230148460716009\n",
      "EarlyStopping 300 / 1 counter: 1 out of 500\n",
      "[20200207T182636] Epock 300 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003264145227149129\n",
      "EarlyStopping 301 / 1 counter: 2 out of 500\n",
      "[20200207T182638] Epock 301 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032350055407732725\n",
      "EarlyStopping 302 / 1 counter: 3 out of 500\n",
      "[20200207T182641] Epock 302 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032117452938109636\n",
      "EarlyStopping 303 / 1 counter: 4 out of 500\n",
      "[20200207T182643] Epock 303 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003214097348973155\n",
      "EarlyStopping 304 / 1 counter: 5 out of 500\n",
      "[20200207T182646] Epock 304 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031930223340168595\n",
      "EarlyStopping 305 / 1 counter: 6 out of 500\n",
      "[20200207T182648] Epock 305 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031899678288027644\n",
      "EarlyStopping 306 / 1 counter: 7 out of 500\n",
      "[20200207T182650] Epock 306 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031948797404766083\n",
      "EarlyStopping 307 / 1 counter: 8 out of 500\n",
      "[20200207T182653] Epock 307 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032037311466410756\n",
      "EarlyStopping 308 / 1 counter: 9 out of 500\n",
      "[20200207T182655] Epock 308 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031895777210593224\n",
      "Validation loss decreased (0.00318975 --> 0.00318958).  Saving model ...\n",
      "[20200207T182658] Epock 309 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031921807676553726\n",
      "EarlyStopping 310 / 1 counter: 1 out of 500\n",
      "[20200207T182700] Epock 310 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003215281176380813\n",
      "EarlyStopping 311 / 1 counter: 2 out of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200207T182703] Epock 311 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003249557572416961\n",
      "EarlyStopping 312 / 1 counter: 3 out of 500\n",
      "[20200207T182705] Epock 312 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003193655633367598\n",
      "EarlyStopping 313 / 1 counter: 4 out of 500\n",
      "[20200207T182707] Epock 313 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032380307093262672\n",
      "EarlyStopping 314 / 1 counter: 5 out of 500\n",
      "[20200207T182710] Epock 314 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031989034032449126\n",
      "EarlyStopping 315 / 1 counter: 6 out of 500\n",
      "[20200207T182712] Epock 315 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032519280212000012\n",
      "EarlyStopping 316 / 1 counter: 7 out of 500\n",
      "[20200207T182714] Epock 316 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032009041169658303\n",
      "EarlyStopping 317 / 1 counter: 8 out of 500\n",
      "[20200207T182717] Epock 317 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003190461895428598\n",
      "EarlyStopping 318 / 1 counter: 9 out of 500\n",
      "[20200207T182719] Epock 318 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003229873371310532\n",
      "EarlyStopping 319 / 1 counter: 10 out of 500\n",
      "[20200207T182721] Epock 319 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003199223894625902\n",
      "EarlyStopping 320 / 1 counter: 11 out of 500\n",
      "[20200207T182724] Epock 320 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003190469811670482\n",
      "EarlyStopping 321 / 1 counter: 12 out of 500\n",
      "[20200207T182726] Epock 321 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.00320452474988997\n",
      "EarlyStopping 322 / 1 counter: 13 out of 500\n",
      "[20200207T182729] Epock 322 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003190787392668426\n",
      "EarlyStopping 323 / 1 counter: 14 out of 500\n",
      "[20200207T182731] Epock 323 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003227117587812245\n",
      "EarlyStopping 324 / 1 counter: 15 out of 500\n",
      "[20200207T182733] Epock 324 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031886344077065587\n",
      "Validation loss decreased (0.00318958 --> 0.00318863).  Saving model ...\n",
      "[20200207T182736] Epock 325 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031957774190232158\n",
      "EarlyStopping 326 / 1 counter: 1 out of 500\n",
      "[20200207T182739] Epock 326 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032267303904518485\n",
      "EarlyStopping 327 / 1 counter: 2 out of 500\n",
      "[20200207T182741] Epock 327 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003284987178631127\n",
      "EarlyStopping 328 / 1 counter: 3 out of 500\n",
      "[20200207T182743] Epock 328 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003192191827110946\n",
      "EarlyStopping 329 / 1 counter: 4 out of 500\n",
      "[20200207T182746] Epock 329 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032557605300098658\n",
      "EarlyStopping 330 / 1 counter: 5 out of 500\n",
      "[20200207T182748] Epock 330 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031977820908650756\n",
      "EarlyStopping 331 / 1 counter: 6 out of 500\n",
      "[20200207T182750] Epock 331 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003189573297277093\n",
      "EarlyStopping 332 / 1 counter: 7 out of 500\n",
      "[20200207T182753] Epock 332 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003188755945302546\n",
      "EarlyStopping 333 / 1 counter: 8 out of 500\n",
      "[20200207T182755] Epock 333 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003189162351191044\n",
      "EarlyStopping 334 / 1 counter: 9 out of 500\n",
      "[20200207T182757] Epock 334 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003188537899404764\n",
      "Validation loss decreased (0.00318863 --> 0.00318854).  Saving model ...\n",
      "[20200207T182800] Epock 335 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003188308095559478\n",
      "Validation loss decreased (0.00318854 --> 0.00318831).  Saving model ...\n",
      "[20200207T182803] Epock 336 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032007923582568765\n",
      "EarlyStopping 337 / 1 counter: 1 out of 500\n",
      "[20200207T182805] Epock 337 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003213298274204135\n",
      "EarlyStopping 338 / 1 counter: 2 out of 500\n",
      "[20200207T182808] Epock 338 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003193029435351491\n",
      "EarlyStopping 339 / 1 counter: 3 out of 500\n",
      "[20200207T182810] Epock 339 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003189397626556456\n",
      "EarlyStopping 340 / 1 counter: 4 out of 500\n",
      "[20200207T182812] Epock 340 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032923483522608876\n",
      "EarlyStopping 341 / 1 counter: 5 out of 500\n",
      "[20200207T182815] Epock 341 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032329974928870797\n",
      "EarlyStopping 342 / 1 counter: 6 out of 500\n",
      "[20200207T182817] Epock 342 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003192524309270084\n",
      "EarlyStopping 343 / 1 counter: 7 out of 500\n",
      "[20200207T182819] Epock 343 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003202416584827006\n",
      "EarlyStopping 344 / 1 counter: 8 out of 500\n",
      "[20200207T182822] Epock 344 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.003227043431252241\n",
      "EarlyStopping 345 / 1 counter: 9 out of 500\n",
      "[20200207T182824] Epock 345 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.00319997884798795\n",
      "EarlyStopping 346 / 1 counter: 10 out of 500\n",
      "[20200207T182826] Epock 346 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0032065141713246703\n",
      "EarlyStopping 347 / 1 counter: 11 out of 500\n",
      "[20200207T182829] Epock 347 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031883190385997295\n",
      "EarlyStopping 348 / 1 counter: 12 out of 500\n",
      "[20200207T182831] Epock 348 / 400\t lr 7.8125e-05\n",
      "  train_loss: 0.0031880768947303295\n",
      "Validation loss decreased (0.00318831 --> 0.00318808).  Saving model ...\n",
      "[20200207T182834] Epock 349 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003189688199199736\n",
      "EarlyStopping 350 / 1 counter: 1 out of 500\n",
      "[20200207T182836] Epock 350 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003188438480719924\n",
      "EarlyStopping 351 / 1 counter: 2 out of 500\n",
      "[20200207T182839] Epock 351 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031879813177511096\n",
      "Validation loss decreased (0.00318808 --> 0.00318798).  Saving model ...\n",
      "[20200207T182842] Epock 352 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032278443686664104\n",
      "EarlyStopping 353 / 1 counter: 1 out of 500\n",
      "[20200207T182844] Epock 353 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032252580858767033\n",
      "EarlyStopping 354 / 1 counter: 2 out of 500\n",
      "[20200207T182846] Epock 354 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032126723090186715\n",
      "EarlyStopping 355 / 1 counter: 3 out of 500\n",
      "[20200207T182849] Epock 355 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031977177131921053\n",
      "EarlyStopping 356 / 1 counter: 4 out of 500\n",
      "[20200207T182851] Epock 356 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003199388156645\n",
      "EarlyStopping 357 / 1 counter: 5 out of 500\n",
      "[20200207T182853] Epock 357 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031997524201869965\n",
      "EarlyStopping 358 / 1 counter: 6 out of 500\n",
      "[20200207T182856] Epock 358 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003195630037225783\n",
      "EarlyStopping 359 / 1 counter: 7 out of 500\n",
      "[20200207T182858] Epock 359 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003187766997143626\n",
      "Validation loss decreased (0.00318798 --> 0.00318777).  Saving model ...\n",
      "[20200207T182901] Epock 360 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032143363496288657\n",
      "EarlyStopping 361 / 1 counter: 1 out of 500\n",
      "[20200207T182903] Epock 361 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003187195979990065\n",
      "Validation loss decreased (0.00318777 --> 0.00318720).  Saving model ...\n",
      "[20200207T182906] Epock 362 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003196192323230207\n",
      "EarlyStopping 363 / 1 counter: 1 out of 500\n",
      "[20200207T182909] Epock 363 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031945795053616166\n",
      "EarlyStopping 364 / 1 counter: 2 out of 500\n",
      "[20200207T182911] Epock 364 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032075184863060713\n",
      "EarlyStopping 365 / 1 counter: 3 out of 500\n",
      "[20200207T182913] Epock 365 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031911623664200306\n",
      "EarlyStopping 366 / 1 counter: 4 out of 500\n",
      "[20200207T182916] Epock 366 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.00321884173899889\n",
      "EarlyStopping 367 / 1 counter: 5 out of 500\n",
      "[20200207T182918] Epock 367 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032124537974596024\n",
      "EarlyStopping 368 / 1 counter: 6 out of 500\n",
      "[20200207T182920] Epock 368 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031855598790571094\n",
      "Validation loss decreased (0.00318720 --> 0.00318556).  Saving model ...\n",
      "[20200207T182923] Epock 369 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032223399030044675\n",
      "EarlyStopping 370 / 1 counter: 1 out of 500\n",
      "[20200207T182926] Epock 370 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003206154447980225\n",
      "EarlyStopping 371 / 1 counter: 2 out of 500\n",
      "[20200207T182928] Epock 371 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003185295150615275\n",
      "Validation loss decreased (0.00318556 --> 0.00318530).  Saving model ...\n",
      "[20200207T182931] Epock 372 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032264130422845483\n",
      "EarlyStopping 373 / 1 counter: 1 out of 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20200207T182933] Epock 373 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031954755540937185\n",
      "EarlyStopping 374 / 1 counter: 2 out of 500\n",
      "[20200207T182936] Epock 374 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003220618120394647\n",
      "EarlyStopping 375 / 1 counter: 3 out of 500\n",
      "[20200207T182938] Epock 375 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032027263659983873\n",
      "EarlyStopping 376 / 1 counter: 4 out of 500\n",
      "[20200207T182940] Epock 376 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031945870723575354\n",
      "EarlyStopping 377 / 1 counter: 5 out of 500\n",
      "[20200207T182943] Epock 377 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003183795139193535\n",
      "Validation loss decreased (0.00318530 --> 0.00318380).  Saving model ...\n",
      "[20200207T182945] Epock 378 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031931798439472914\n",
      "EarlyStopping 379 / 1 counter: 1 out of 500\n",
      "[20200207T182948] Epock 379 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031863506883382797\n",
      "EarlyStopping 380 / 1 counter: 2 out of 500\n",
      "[20200207T182950] Epock 380 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003184633795171976\n",
      "EarlyStopping 381 / 1 counter: 3 out of 500\n",
      "[20200207T182952] Epock 381 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003184474306181073\n",
      "EarlyStopping 382 / 1 counter: 4 out of 500\n",
      "[20200207T182955] Epock 382 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032073822803795338\n",
      "EarlyStopping 383 / 1 counter: 5 out of 500\n",
      "[20200207T182957] Epock 383 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003184429951943457\n",
      "EarlyStopping 384 / 1 counter: 6 out of 500\n",
      "[20200207T183000] Epock 384 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0032295077107846737\n",
      "EarlyStopping 385 / 1 counter: 7 out of 500\n",
      "[20200207T183002] Epock 385 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031910225516185164\n",
      "EarlyStopping 386 / 1 counter: 8 out of 500\n",
      "[20200207T183004] Epock 386 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031833742978051305\n",
      "Validation loss decreased (0.00318380 --> 0.00318337).  Saving model ...\n",
      "[20200207T183007] Epock 387 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031834724359214306\n",
      "EarlyStopping 388 / 1 counter: 1 out of 500\n",
      "[20200207T183009] Epock 388 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031839567236602306\n",
      "EarlyStopping 389 / 1 counter: 2 out of 500\n",
      "[20200207T183012] Epock 389 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003224470536224544\n",
      "EarlyStopping 390 / 1 counter: 3 out of 500\n",
      "[20200207T183014] Epock 390 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031829114304855466\n",
      "Validation loss decreased (0.00318337 --> 0.00318291).  Saving model ...\n",
      "[20200207T183017] Epock 391 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031836683629080653\n",
      "EarlyStopping 392 / 1 counter: 1 out of 500\n",
      "[20200207T183020] Epock 392 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031882859766483307\n",
      "EarlyStopping 393 / 1 counter: 2 out of 500\n",
      "[20200207T183022] Epock 393 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003189051989465952\n",
      "EarlyStopping 394 / 1 counter: 3 out of 500\n",
      "[20200207T183024] Epock 394 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031878880690783262\n",
      "EarlyStopping 395 / 1 counter: 4 out of 500\n",
      "[20200207T183027] Epock 395 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031834844266995788\n",
      "EarlyStopping 396 / 1 counter: 5 out of 500\n",
      "[20200207T183029] Epock 396 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.0031832295935600996\n",
      "EarlyStopping 397 / 1 counter: 6 out of 500\n",
      "[20200207T183031] Epock 397 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003213681513443589\n",
      "EarlyStopping 398 / 1 counter: 7 out of 500\n",
      "[20200207T183034] Epock 398 / 400\t lr 3.90625e-05\n",
      "  train_loss: 0.003191237454302609\n",
      "EarlyStopping 399 / 1 counter: 8 out of 500\n",
      "[20200207T183036] Epock 399 / 400\t lr 1.953125e-05\n",
      "  train_loss: 0.0031837805872783065\n",
      "EarlyStopping 400 / 1 counter: 9 out of 500\n",
      "\n",
      "model/20200207T164850_0.0031829114304855466.model\n"
     ]
    }
   ],
   "source": [
    "# model = AutoEncoder(input_size=len(fea_cols), output_size=128).to(device)\n",
    "\n",
    "total_epoch = 400\n",
    "patience = 500\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, min_epoch=1, verbose=True)\n",
    "early_stopping.val_loss_min = val_loss_min\n",
    "early_stopping.best_score = None if val_loss_min==np.Inf else -val_loss_min \n",
    "\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.015, momentum=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "# scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=100, eta_min=0.00001)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size = 100, gamma=0.5)\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "\n",
    "for e in tqdm_notebook(range(total_epoch), total=total_epoch, desc='Epoch'):\n",
    "    if os.path.isfile('stop.flag'):\n",
    "        print(f'{e} stop!')\n",
    "        break\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, data in enumerate(all_loader):\n",
    "        X_batch, _ = data\n",
    "        X_batch = X_batch.to(device)\n",
    "\n",
    "#     scheduler.step(total_epoch + i / len(all_loader))\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, X_batch)\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss = total_loss / len(all_loader)\n",
    "\n",
    "    ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "    print(f'[{ts}] Epock {e} / {total_epoch}\\t lr {scheduler.get_lr()[0]}')\n",
    "    print(f'  train_loss: {train_loss}')\n",
    "\n",
    "    early_stopping(train_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"\\tEarly stopping epoch {}, valid loss {}\".format(e, early_stopping.val_loss_min))\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "val_loss_min = early_stopping.val_loss_min\n",
    "\n",
    "model_path = 'model/{}_{}.model'.format(model_ts, val_loss_min)\n",
    "joblib.dump(model, model_path)\n",
    "print(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T09:34:02.852754Z",
     "start_time": "2020-02-07T09:34:01.097642Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "X_trains = []\n",
    "y_trains = []\n",
    "for i, data in enumerate(all_loader):\n",
    "    X_batch, y_batch = data\n",
    "    X_batch = X_batch.to(device)\n",
    "    \n",
    "    y_trains.append(y_batch.cpu().detach().numpy())\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        X_pred = model.encoder(X_batch)\n",
    "#         loss = criterion(X_pred, X_batch)\n",
    "#         total_loss = total_loss + loss.item()\n",
    "        \n",
    "    X_trains.append(X_pred.cpu().detach().numpy())\n",
    "\n",
    "# print(total_loss / len(all_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T09:39:47.981788Z",
     "start_time": "2020-02-07T09:39:47.974346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(np.concatenate(X_trains))\n",
    "fea_cols = list(train.columns)\n",
    "fea_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T09:39:48.864565Z",
     "start_time": "2020-02-07T09:39:48.861277Z"
    }
   },
   "outputs": [],
   "source": [
    "train['label'] = np.concatenate(y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T09:39:49.263764Z",
     "start_time": "2020-02-07T09:39:49.239925Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>4.865262e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999140</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>4.504285e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999001</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>2.735852e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.998988</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>2.754486e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>3.535596e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41395</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>5.325680e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41396</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999158</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>4.062645e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41397</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999245</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>5.478985e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41398</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999003</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>2.673643e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41399</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>5.703962e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41400 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.000007  0.000003  0.000006  0.000021  0.999939  0.999197  0.999997   \n",
       "1      0.000007  0.000003  0.000006  0.000021  0.999939  0.999140  0.999997   \n",
       "2      0.000006  0.000002  0.000005  0.000020  0.999946  0.999001  0.999998   \n",
       "3      0.000006  0.000002  0.000005  0.000020  0.999946  0.998988  0.999998   \n",
       "4      0.000007  0.000003  0.000005  0.000021  0.999942  0.999066  0.999997   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "41395  0.000007  0.000003  0.000006  0.000020  0.999939  0.999250  0.999997   \n",
       "41396  0.000007  0.000003  0.000006  0.000020  0.999942  0.999158  0.999997   \n",
       "41397  0.000007  0.000003  0.000006  0.000021  0.999938  0.999245  0.999997   \n",
       "41398  0.000006  0.000002  0.000005  0.000020  0.999947  0.999003  0.999998   \n",
       "41399  0.000007  0.000003  0.000006  0.000021  0.999937  0.999243  0.999997   \n",
       "\n",
       "              7         8             9  ...       119       120       121  \\\n",
       "0      0.000009  0.999985  4.865262e-08  ...  0.000021  0.000016  0.999992   \n",
       "1      0.000008  0.999984  4.504285e-08  ...  0.000021  0.000016  0.999992   \n",
       "2      0.000007  0.999985  2.735852e-08  ...  0.000017  0.000014  0.999994   \n",
       "3      0.000007  0.999985  2.754486e-08  ...  0.000017  0.000014  0.999994   \n",
       "4      0.000007  0.999985  3.535596e-08  ...  0.000019  0.000015  0.999993   \n",
       "...         ...       ...           ...  ...       ...       ...       ...   \n",
       "41395  0.000009  0.999985  5.325680e-08  ...  0.000022  0.000016  0.999992   \n",
       "41396  0.000008  0.999985  4.062645e-08  ...  0.000020  0.000015  0.999993   \n",
       "41397  0.000009  0.999985  5.478985e-08  ...  0.000022  0.000016  0.999992   \n",
       "41398  0.000007  0.999985  2.673643e-08  ...  0.000017  0.000014  0.999994   \n",
       "41399  0.000009  0.999984  5.703962e-08  ...  0.000023  0.000017  0.999992   \n",
       "\n",
       "            122  123       124  125       126       127  label  \n",
       "0      0.999487  1.0  0.999994  1.0  0.000729  0.999995    118  \n",
       "1      0.999586  1.0  0.999994  1.0  0.000748  0.999995    155  \n",
       "2      0.999793  1.0  0.999995  1.0  0.000701  0.999996    117  \n",
       "3      0.999798  1.0  0.999995  1.0  0.000710  0.999996    113  \n",
       "4      0.999711  1.0  0.999995  1.0  0.000730  0.999995    114  \n",
       "...         ...  ...       ...  ...       ...       ...    ...  \n",
       "41395  0.999359  1.0  0.999994  1.0  0.000715  0.999994    181  \n",
       "41396  0.999594  1.0  0.999995  1.0  0.000709  0.999995    114  \n",
       "41397  0.999358  1.0  0.999994  1.0  0.000726  0.999994    122  \n",
       "41398  0.999795  1.0  0.999995  1.0  0.000694  0.999996    118  \n",
       "41399  0.999344  1.0  0.999994  1.0  0.000738  0.999994     68  \n",
       "\n",
       "[41400 rows x 129 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T09:40:40.823907Z",
     "start_time": "2020-02-07T09:40:40.817960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_ts 20200207T184040\n",
      "{'boosting': 'gbdt', 'num_leaves': 7, 'num_class': 198, 'objective': 'multiclass', 'metric': 'multi_logloss', 'num_threads': 16, 'learning_rate': 0.01, 'is_unbalance': True, 'bagging_fraction': 1, 'feature_fraction': 1, 'initscore_filename': '', 'device_type': 'gpu'}\n",
      "{}\n",
      "num_round: 10000\n"
     ]
    }
   ],
   "source": [
    "model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "print('model_ts', model_ts)\n",
    "\n",
    "initscore_filename = ''\n",
    "params = {\n",
    "    'boosting':'gbdt',\n",
    "#     'boosting':'dart',\n",
    "#     'boosting':'goss',\n",
    "    'num_leaves': 7,\n",
    "#     'max_depth': 3,\n",
    "    'num_class':num_class,\n",
    "    'objective': 'multiclass',\n",
    "    'metric':'multi_logloss',\n",
    "    'num_threads': 16,\n",
    "    'learning_rate': 0.01,\n",
    "    'is_unbalance': True,\n",
    "#     'scale_pos_weight':200,\n",
    "    'bagging_fraction':1,\n",
    "#     'bagging_freq':5,\n",
    "    'feature_fraction':1,\n",
    "    'initscore_filename':initscore_filename,\n",
    "#     'lambda_l1':200,\n",
    "#     'lambda_l2':20,\n",
    "    'device_type':'gpu',\n",
    "#     'tree_learner':'data',\n",
    "\n",
    "}\n",
    "print(params)\n",
    "\n",
    "data_params = {\n",
    "#     'max_bin':127,\n",
    "#     'enable_bundle': False,\n",
    "}\n",
    "print(data_params)\n",
    "\n",
    "num_round = 10000\n",
    "print('num_round:', num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T09:46:04.739063Z",
     "start_time": "2020-02-07T09:40:41.558944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df7f21a492b479f83080faf5df6d1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='CV', max=10, style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37260, 128) (4140, 128)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 3.89152\tvalid_1's multi_logloss: 4.02554\n",
      "[100]\ttraining's multi_logloss: 3.58212\tvalid_1's multi_logloss: 3.77981\n",
      "[150]\ttraining's multi_logloss: 3.39063\tvalid_1's multi_logloss: 3.63879\n",
      "[200]\ttraining's multi_logloss: 3.25662\tvalid_1's multi_logloss: 3.549\n",
      "[250]\ttraining's multi_logloss: 3.15739\tvalid_1's multi_logloss: 3.48882\n",
      "[300]\ttraining's multi_logloss: 3.08014\tvalid_1's multi_logloss: 3.44781\n",
      "[350]\ttraining's multi_logloss: 3.01747\tvalid_1's multi_logloss: 3.4184\n",
      "[400]\ttraining's multi_logloss: 2.96483\tvalid_1's multi_logloss: 3.39819\n",
      "[450]\ttraining's multi_logloss: 2.91962\tvalid_1's multi_logloss: 3.3844\n",
      "[500]\ttraining's multi_logloss: 2.88061\tvalid_1's multi_logloss: 3.37492\n",
      "[550]\ttraining's multi_logloss: 2.8458\tvalid_1's multi_logloss: 3.36837\n",
      "[600]\ttraining's multi_logloss: 2.81417\tvalid_1's multi_logloss: 3.36393\n",
      "[650]\ttraining's multi_logloss: 2.7845\tvalid_1's multi_logloss: 3.36179\n",
      "[700]\ttraining's multi_logloss: 2.75663\tvalid_1's multi_logloss: 3.36109\n",
      "[750]\ttraining's multi_logloss: 2.73042\tvalid_1's multi_logloss: 3.36104\n",
      "[800]\ttraining's multi_logloss: 2.70488\tvalid_1's multi_logloss: 3.36162\n",
      "[850]\ttraining's multi_logloss: 2.68012\tvalid_1's multi_logloss: 3.36305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-b0f76dbcce7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                             \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                             \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#                             init_model=model,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                            )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "submit_csv = []\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=81511991154 % 2**32-1, shuffle=True)\n",
    "\n",
    "cv = 0\n",
    "for train_index, valid_index in tqdm_notebook(skf.split(train.index, train['label'].values), total=n_splits, desc = 'CV'):\n",
    "    \n",
    "    X_train, X_test = train.loc[train_index, fea_cols], train.loc[valid_index, fea_cols] \n",
    "    y_train, y_test = train.loc[train_index,'label'], train.loc[valid_index, 'label']    \n",
    "    \n",
    "    print(X_train.shape, X_test.shape)\n",
    "    \n",
    "    train_set = lgb.Dataset(X_train, label=y_train, params=data_params)\n",
    "    val_set = lgb.Dataset(X_test, label=y_test, params=data_params)\n",
    "\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, train_set, num_round, early_stopping_rounds=200, \n",
    "                            valid_sets=[train_set, val_set],\n",
    "                            verbose_eval=50,\n",
    "                            evals_result=evals_result,\n",
    "#                             init_model=model,\n",
    "                           )\n",
    "\n",
    "    model_tag ='{}_{}_{}_{}'.format(model_ts, cv,\n",
    "                                 evals_result['valid_1']['multi_logloss'][model.best_iteration-1],\n",
    "                                 evals_result['training']['multi_logloss'][model.best_iteration-1]\n",
    "                                )\n",
    "    print(model_tag)\n",
    "\n",
    "    joblib.dump(model, 'model/{}.model'.format(model_tag))\n",
    "    \n",
    "    \n",
    "    pred = model.predict(test[fea_cols])\n",
    "\n",
    "    submission = pd.DataFrame(data=pred)\n",
    "    submission.index = test.index\n",
    "    submission.index.name = 'id'\n",
    "    submission = submission.sort_index()\n",
    "    submission = submission.groupby('id').mean()\n",
    "\n",
    "    csv_path = 'submit/{}.csv'.format(model_tag)\n",
    "    submit_csv.append(csv_path)\n",
    "    submission.to_csv(csv_path, index=True) \n",
    "    \n",
    "    print(submission.sum(axis=1))\n",
    "    print(submission)\n",
    "    cv += 1\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T00:58:49.539855Z",
     "start_time": "2020-02-07T00:58:49.372260Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DNNModel(input_size=len(fea_cols), dropout_probability=0).to(device)\n",
    "# model = CNNModel(dropout_probability=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T00:58:49.542574Z",
     "start_time": "2020-02-07T00:58:49.540908Z"
    }
   },
   "outputs": [],
   "source": [
    "val_loss_min = np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T00:58:49.550792Z",
     "start_time": "2020-02-07T00:58:49.543275Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# criterion(torch.Tensor([[0,0,1]]), torch.Tensor([[0.1,0.2, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:18:36.468658Z",
     "start_time": "2020-02-07T02:18:36.463675Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "\n",
    "# # criterion = nn.MultiLabelSoftMarginLoss().to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# scheduler = StepLR(optimizer, step_size=50, gamma=1.0)\n",
    "\n",
    "# trainer = Trainer(model, criterion, optimizer, scheduler, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:18:37.526028Z",
     "start_time": "2020-02-07T02:18:37.524006Z"
    }
   },
   "outputs": [],
   "source": [
    "# lr_list = [\n",
    "# #     (0.1, 20),\n",
    "#     (0.01, 100),\n",
    "#     (0.003, 50),\n",
    "#     (0.001, 50),\n",
    "#     (0.0003, 50),\n",
    "#     (0.0001, 50),\n",
    "#     (0.00003, 50),\n",
    "#     (0.00001, 50),\n",
    "#     (0.000005, 50),\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:28:57.001750Z",
     "start_time": "2020-02-07T04:06:29.852867Z"
    }
   },
   "outputs": [],
   "source": [
    "total_epoch = 10000\n",
    "patience = 200\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, min_epoch=1, verbose=True)\n",
    "early_stopping.val_loss_min = val_loss_min\n",
    "early_stopping.best_score = None if val_loss_min==np.Inf else -val_loss_min \n",
    "\n",
    "model = DNNModel(input_size=len(fea_cols), dropout_probability=0.3).to(device)\n",
    "\n",
    "# trainer.optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     trainer.optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.03, momentum=0.5)\n",
    "\n",
    "# trainer.scheduler = StepLR(trainer.optimizer, step_size=50, gamma=1.0)\n",
    "scheduler = CosineAnnealingWarmRestarts(trainer.optimizer, T_0=500)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean').to(device)\n",
    "\n",
    "trainer = Trainer(model, criterion, optimizer, scheduler, device)\n",
    "\n",
    "\n",
    "for e in tqdm_notebook(range(total_epoch), total=total_epoch, desc='Epoch'):\n",
    "    if os.path.isfile('stop.flag'):\n",
    "        print(f'{e} stop!')\n",
    "        break\n",
    "\n",
    "    train_loss = trainer.train(train_loader, e)\n",
    "\n",
    "    if e % 1 == 0:\n",
    "        valid_loss = trainer.eval(val_loader)\n",
    "#         valid_loss = train_loss\n",
    "\n",
    "        ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "        print(f'[{ts}] Epock {e} / {total_epoch}\\t lr {trainer.scheduler.get_lr()[0]}')\n",
    "        print(f'  train_loss: {train_loss}  valid_loss: {valid_loss}')\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\tEarly stopping epoch {}, valid loss {}\".format(e, early_stopping.val_loss_min))\n",
    "            break\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('model/checkpoint.pt'))\n",
    "val_loss_min = early_stopping.val_loss_min\n",
    "\n",
    "model_path = 'model/{}_{}'.format(model_ts, val_loss_min)\n",
    "trainer.save('{}.model'.format(model_path))\n",
    "print(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T01:24:44.596493Z",
     "start_time": "2020-02-07T00:58:51.351326Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total_epoch = 10000\n",
    "\n",
    "# for lr, patience in lr_list:\n",
    "#     print(lr, patience)\n",
    "#     if os.path.isfile('stop.flag'):\n",
    "#         print('stop!')\n",
    "#         break\n",
    "    \n",
    "#     early_stopping = EarlyStopping(patience=patience, min_epoch=1, verbose=True)\n",
    "#     early_stopping.val_loss_min = val_loss_min\n",
    "#     early_stopping.best_score = None if val_loss_min==np.Inf else -val_loss_min \n",
    "    \n",
    "#     trainer.optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# #     trainer.optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "# #     trainer.optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "#     trainer.scheduler = StepLR(trainer.optimizer, step_size=50, gamma=1.0)\n",
    "    \n",
    "#     for e in tqdm_notebook(range(total_epoch), total=total_epoch, desc='Epoch'):\n",
    "#         if os.path.isfile('stop.flag'):\n",
    "#             print(f'{e} stop!')\n",
    "#             break\n",
    "\n",
    "#         train_loss = trainer.train(train_loader)\n",
    "        \n",
    "#         if e % 1 == 0:\n",
    "#             valid_loss = trainer.eval(val_loader)\n",
    "#     #         valid_loss = train_loss\n",
    "\n",
    "#             ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "#             print(f'[{ts}] Epock {e} / {total_epoch}\\t lr {trainer.scheduler.get_lr()[0]}')\n",
    "#             print(f'  train_loss: {train_loss}  valid_loss: {valid_loss}')\n",
    "\n",
    "#             early_stopping(valid_loss, model)\n",
    "\n",
    "#             if early_stopping.early_stop:\n",
    "#                 print(\"\\tEarly stopping epoch {}, valid loss {}\".format(e, early_stopping.val_loss_min))\n",
    "#                 break\n",
    "            \n",
    "\n",
    "#     model.load_state_dict(torch.load('model/checkpoint.pt'))\n",
    "# #     trainer.load('model/checkpoint.pt')\n",
    "#     val_loss_min = early_stopping.val_loss_min\n",
    "    \n",
    "    \n",
    "#     model_path = 'model/{}_{}'.format(model_ts, val_loss_min)\n",
    "# #     joblib.dump(model, '{}.model'.format(model_path))\n",
    "# #     torch.save(model.state_dict(), '{}.pt'.format(model_path))\n",
    "#     trainer.save('{}.model'.format(model_path))\n",
    "#     print(model_path)\n",
    "\n",
    "#     # torch.save(model.state_dict(), f'checkpoint.pt.{train_loss}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T01:05:32.453591Z",
     "start_time": "2020-02-03T01:05:32.346871Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = joblib.load('model/20200202T232911_0.7551849484443665.model').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T01:06:01.271962Z",
     "start_time": "2020-02-03T01:05:42.664894Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test = data_loader_all_v2(data_loader_v2, test_list, folder=test_folder, train_label=None, event_time=10, nrows=None)\n",
    "print(test.shape)\n",
    "# test[fea_cols] = scaler.transform(test[fea_cols].values)\n",
    "\n",
    "model.eval()\n",
    "y_pred = model(torch.Tensor(test[fea_cols].values))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T01:06:47.409273Z",
     "start_time": "2020-02-03T01:06:47.391034Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = F.softmax(y_pred)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T01:07:10.383341Z",
     "start_time": "2020-02-03T01:07:10.381038Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_tag ='{}_{}_{}'.format(model_ts, train_loss, valid_loss)\n",
    "model_tag ='{}'.format(model_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T01:07:12.160736Z",
     "start_time": "2020-02-03T01:07:12.022397Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=y_pred.cpu().detach().numpy())\n",
    "submission.index = test.index\n",
    "submission.index.name = 'id'\n",
    "submission = submission.sort_index()\n",
    "submission = submission.groupby('id').mean()\n",
    "\n",
    "submission.to_csv('submit/{}.csv'.format(model_tag), index=True) \n",
    "model_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T01:07:12.960508Z",
     "start_time": "2020-02-03T01:07:12.931436Z"
    }
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
