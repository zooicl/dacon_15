{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:00:44.681668Z",
     "start_time": "2020-02-04T05:00:43.901662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiden/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import multiprocessing # 여러 개의 일꾼 (cpu)들에게 작업을 분산시키는 역할\n",
    "from multiprocessing import Pool \n",
    "from functools import partial # 함수가 받는 인자들 중 몇개를 고정 시켜서 새롭게 파생된 함수를 형성하는 역할\n",
    "from data_loader import data_loader_v2 # 자체적으로 만든 data loader version 2.0 ([데이콘 15회 대회] 데이터 설명 및 데이터 불러오기 영상 참조)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib # 모델을 저장하고 불러오는 역\n",
    "from datetime import datetime\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from tools import eval_summary, save_feature_importance, merge_preds, report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:00:44.685273Z",
     "start_time": "2020-02-04T05:00:44.683290Z"
    }
   },
   "outputs": [],
   "source": [
    "train_folder = 'data/train/'\n",
    "test_folder = 'data/test/'\n",
    "train_label_path = 'data/train_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:00:44.701644Z",
     "start_time": "2020-02-04T05:00:44.687681Z"
    }
   },
   "outputs": [],
   "source": [
    "train_list = os.listdir(train_folder)\n",
    "test_list = os.listdir(test_folder)\n",
    "train_label = pd.read_csv(train_label_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:00:44.705949Z",
     "start_time": "2020-02-04T05:00:44.702709Z"
    }
   },
   "outputs": [],
   "source": [
    "num_class = len(train_label['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:00:44.711817Z",
     "start_time": "2020-02-04T05:00:44.706700Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모든 csv 파일의 상태_B로 변화는 시점이 같다라고 가정\n",
    "# 하지만, 개별 csv파일의 상태_B로 변화는 시점은 상이할 수 있음\n",
    "def data_loader_all_v2(func, files, folder='', train_label=None, event_time=10, nrows=60):   \n",
    "    func_fixed = partial(func, folder=folder, train_label=train_label, event_time=event_time, nrows=nrows)     \n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(processes=multiprocessing.cpu_count()-2) \n",
    "        df_list = list(pool.imap(func_fixed, files)) \n",
    "        pool.close()\n",
    "        pool.join()        \n",
    "    combined_df = pd.concat(df_list)    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:00:44.717661Z",
     "start_time": "2020-02-04T05:00:44.712549Z"
    }
   },
   "outputs": [],
   "source": [
    "# event_time = 10\n",
    "# nrows = 20\n",
    "# train = data_loader_all_v2(data_loader_v2, train_list, folder=train_folder, train_label=train_label, \n",
    "#                            event_time=10, nrows=60)\n",
    "# print(train.shape)\n",
    "# joblib.dump(train, 'data/df_train_{}_{}.pkl'.format(event_time, nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:00:44.725177Z",
     "start_time": "2020-02-04T05:00:44.718429Z"
    }
   },
   "outputs": [],
   "source": [
    "# event_time = 10\n",
    "# nrows = 20\n",
    "# test = data_loader_all_v2(data_loader_v2, test_list, folder=test_folder, train_label=None, event_time=10, nrows=None)\n",
    "# print(test.shape)\n",
    "# joblib.dump(train, 'data/df_test_{}_{}.pkl'.format(event_time, nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:00:49.390138Z",
     "start_time": "2020-02-04T05:00:45.272651Z"
    }
   },
   "outputs": [],
   "source": [
    "train = joblib.load('data/df_train_10_60.pkl')\n",
    "test = joblib.load('data/df_test_10.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:00:59.918776Z",
     "start_time": "2020-02-04T05:00:59.854316Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>V0000</th>\n",
       "      <th>V0001</th>\n",
       "      <th>V0002</th>\n",
       "      <th>V0003</th>\n",
       "      <th>V0004</th>\n",
       "      <th>V0005</th>\n",
       "      <th>V0006</th>\n",
       "      <th>V0007</th>\n",
       "      <th>V0008</th>\n",
       "      <th>...</th>\n",
       "      <th>V5112</th>\n",
       "      <th>V5113</th>\n",
       "      <th>V5114</th>\n",
       "      <th>V5115</th>\n",
       "      <th>V5116</th>\n",
       "      <th>V5117</th>\n",
       "      <th>V5118</th>\n",
       "      <th>V5119</th>\n",
       "      <th>V5120</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>30.464769</td>\n",
       "      <td>8.677597</td>\n",
       "      <td>8.702804</td>\n",
       "      <td>8.730314</td>\n",
       "      <td>8.710375</td>\n",
       "      <td>188.466110</td>\n",
       "      <td>192.279094</td>\n",
       "      <td>3.577269e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.235258e-08</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>30.464943</td>\n",
       "      <td>8.791777</td>\n",
       "      <td>8.741013</td>\n",
       "      <td>8.713725</td>\n",
       "      <td>8.719421</td>\n",
       "      <td>217.356293</td>\n",
       "      <td>180.249471</td>\n",
       "      <td>1.489698e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.374557e-05</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>30.488713</td>\n",
       "      <td>8.727617</td>\n",
       "      <td>8.704063</td>\n",
       "      <td>8.735527</td>\n",
       "      <td>8.695147</td>\n",
       "      <td>211.251065</td>\n",
       "      <td>203.137411</td>\n",
       "      <td>-4.623827e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.323392e-07</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>30.480049</td>\n",
       "      <td>8.648655</td>\n",
       "      <td>8.703581</td>\n",
       "      <td>8.701050</td>\n",
       "      <td>8.712508</td>\n",
       "      <td>191.682448</td>\n",
       "      <td>229.797028</td>\n",
       "      <td>-4.555857e-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.886027e-07</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>30.458851</td>\n",
       "      <td>8.775581</td>\n",
       "      <td>8.692660</td>\n",
       "      <td>8.668370</td>\n",
       "      <td>8.693597</td>\n",
       "      <td>171.733996</td>\n",
       "      <td>197.299448</td>\n",
       "      <td>2.670567e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.486860e-06</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41395</td>\n",
       "      <td>412</td>\n",
       "      <td>30.464380</td>\n",
       "      <td>8.756510</td>\n",
       "      <td>8.704116</td>\n",
       "      <td>8.708070</td>\n",
       "      <td>8.695244</td>\n",
       "      <td>204.176503</td>\n",
       "      <td>161.976163</td>\n",
       "      <td>2.251255e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.459667e-06</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41396</td>\n",
       "      <td>412</td>\n",
       "      <td>30.469418</td>\n",
       "      <td>8.795708</td>\n",
       "      <td>8.710370</td>\n",
       "      <td>8.675788</td>\n",
       "      <td>8.729044</td>\n",
       "      <td>179.953484</td>\n",
       "      <td>219.859216</td>\n",
       "      <td>4.935893e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.433227e-05</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41397</td>\n",
       "      <td>412</td>\n",
       "      <td>30.496433</td>\n",
       "      <td>8.718257</td>\n",
       "      <td>8.711385</td>\n",
       "      <td>8.743894</td>\n",
       "      <td>8.696282</td>\n",
       "      <td>183.269207</td>\n",
       "      <td>177.435280</td>\n",
       "      <td>2.561626e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.931438e-05</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41398</td>\n",
       "      <td>412</td>\n",
       "      <td>30.486438</td>\n",
       "      <td>8.765540</td>\n",
       "      <td>8.699353</td>\n",
       "      <td>8.699495</td>\n",
       "      <td>8.723896</td>\n",
       "      <td>193.128757</td>\n",
       "      <td>225.198348</td>\n",
       "      <td>-8.936770e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.236397e-06</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41399</td>\n",
       "      <td>412</td>\n",
       "      <td>30.468811</td>\n",
       "      <td>8.747650</td>\n",
       "      <td>8.711092</td>\n",
       "      <td>8.678922</td>\n",
       "      <td>8.726727</td>\n",
       "      <td>198.280429</td>\n",
       "      <td>184.729777</td>\n",
       "      <td>7.671298e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.294326e-05</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41400 rows × 5123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index      V0000     V0001     V0002     V0003     V0004       V0005  \\\n",
       "0        105  30.464769  8.677597  8.702804  8.730314  8.710375  188.466110   \n",
       "1        105  30.464943  8.791777  8.741013  8.713725  8.719421  217.356293   \n",
       "2        105  30.488713  8.727617  8.704063  8.735527  8.695147  211.251065   \n",
       "3        105  30.480049  8.648655  8.703581  8.701050  8.712508  191.682448   \n",
       "4        105  30.458851  8.775581  8.692660  8.668370  8.693597  171.733996   \n",
       "...      ...        ...       ...       ...       ...       ...         ...   \n",
       "41395    412  30.464380  8.756510  8.704116  8.708070  8.695244  204.176503   \n",
       "41396    412  30.469418  8.795708  8.710370  8.675788  8.729044  179.953484   \n",
       "41397    412  30.496433  8.718257  8.711385  8.743894  8.696282  183.269207   \n",
       "41398    412  30.486438  8.765540  8.699353  8.699495  8.723896  193.128757   \n",
       "41399    412  30.468811  8.747650  8.711092  8.678922  8.726727  198.280429   \n",
       "\n",
       "            V0006         V0007  V0008  ...  V5112  V5113  V5114  V5115  \\\n",
       "0      192.279094  3.577269e-19    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "1      180.249471  1.489698e-19    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "2      203.137411 -4.623827e-19    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "3      229.797028 -4.555857e-20    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "4      197.299448  2.670567e-19    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "...           ...           ...    ...  ...    ...    ...    ...    ...   \n",
       "41395  161.976163  2.251255e-19    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "41396  219.859216  4.935893e-19    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "41397  177.435280  2.561626e-19    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "41398  225.198348 -8.936770e-19    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "41399  184.729777  7.671298e-19    0.0  ...    1.0    1.0    1.0   60.0   \n",
       "\n",
       "       V5116  V5117         V5118  V5119  V5120  label  \n",
       "0        0.0    0.0  5.235258e-08   85.4    0.0     77  \n",
       "1        0.0    0.0 -2.374557e-05   85.4    0.0     77  \n",
       "2        0.0    0.0  6.323392e-07   85.4    0.0     77  \n",
       "3        0.0    0.0 -1.886027e-07   85.4    0.0     77  \n",
       "4        0.0    0.0  6.486860e-06   85.4    0.0     77  \n",
       "...      ...    ...           ...    ...    ...    ...  \n",
       "41395    0.0    0.0  9.459667e-06   85.4    0.0     19  \n",
       "41396    0.0    0.0 -3.433227e-05   85.4    0.0     19  \n",
       "41397    0.0    0.0 -1.931438e-05   85.4    0.0     19  \n",
       "41398    0.0    0.0  7.236397e-06   85.4    0.0     19  \n",
       "41399    0.0    0.0 -1.294326e-05   85.4    0.0     19  \n",
       "\n",
       "[41400 rows x 5123 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.reset_index()\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:01:27.016016Z",
     "start_time": "2020-02-04T05:01:27.012043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_cols = [c for c in train.columns if c[0] == 'V']\n",
    "len(fea_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:03:03.449625Z",
     "start_time": "2020-02-04T05:02:44.173063Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train[fea_cols].values)\n",
    "\n",
    "train[fea_cols] = scaler.transform(train[fea_cols].values)\n",
    "test[fea_cols] = scaler.transform(test[fea_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:07:15.007964Z",
     "start_time": "2020-02-04T05:06:52.299347Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 100\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(train[fea_cols].values)\n",
    "\n",
    "cols = ['pca_{}'.format(i) for i in range(n_components)]\n",
    "\n",
    "for c in cols:\n",
    "    train[c] = 0\n",
    "    test[c] = 0\n",
    "train[cols] = pca.transform(train[fea_cols].values)\n",
    "test[cols] = pca.transform(test[fea_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T02:58:30.747560Z",
     "start_time": "2020-02-04T02:58:30.738744Z"
    }
   },
   "outputs": [],
   "source": [
    "# zero_cols = joblib.load('zero_cols.bin')\n",
    "# fea_cols = [c for c in fea_cols if c not in zero_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T02:58:30.752935Z",
     "start_time": "2020-02-04T02:58:30.748562Z"
    }
   },
   "outputs": [],
   "source": [
    "# use_cols = joblib.load('use_cols.bin')\n",
    "# fea_cols = use_cols[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:07:30.875307Z",
     "start_time": "2020-02-04T05:07:30.872388Z"
    }
   },
   "outputs": [],
   "source": [
    "fea_cols = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:07:32.306200Z",
     "start_time": "2020-02-04T05:07:32.302091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fea_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:07:32.788014Z",
     "start_time": "2020-02-04T05:07:32.782527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110    1200\n",
       "17     1050\n",
       "114    1000\n",
       "118    1000\n",
       "117     950\n",
       "       ... \n",
       "137      50\n",
       "52       50\n",
       "51       50\n",
       "42       50\n",
       "191      50\n",
       "Name: label, Length: 198, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:07:33.569322Z",
     "start_time": "2020-02-04T05:07:33.566765Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=81511991154 % 2**32-1)\n",
    "\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:09:15.555439Z",
     "start_time": "2020-02-04T05:09:15.550602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_ts 20200204T140915\n",
      "{'boosting': 'gbdt', 'num_leaves': 7, 'num_class': 198, 'objective': 'multiclass', 'metric': 'multi_logloss', 'num_threads': 2, 'learning_rate': 0.01, 'is_unbalance': True, 'bagging_fraction': 0.1, 'bagging_freq': 5, 'feature_fraction': 0.1, 'initscore_filename': '', 'device_type': 'gpu'}\n",
      "{}\n",
      "num_round: 5000\n"
     ]
    }
   ],
   "source": [
    "model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "print('model_ts', model_ts)\n",
    "\n",
    "initscore_filename = ''\n",
    "params = {\n",
    "    'boosting':'gbdt',\n",
    "#     'boosting':'dart',\n",
    "#     'boosting':'goss',\n",
    "    'num_leaves': 7,\n",
    "#     'max_depth': 3,\n",
    "    'num_class':num_class,\n",
    "    'objective': 'multiclass',\n",
    "    'metric':'multi_logloss',\n",
    "    'num_threads': 2,\n",
    "    'learning_rate': 0.01,\n",
    "    'is_unbalance': True,\n",
    "#     'scale_pos_weight':200,\n",
    "    'bagging_fraction':0.1,\n",
    "    'bagging_freq':5,\n",
    "    'feature_fraction':0.1,\n",
    "    'initscore_filename':initscore_filename,\n",
    "#     'lambda_l1':200,\n",
    "#     'lambda_l2':20,\n",
    "    'device_type':'gpu',\n",
    "#     'tree_learner':'data',\n",
    "\n",
    "}\n",
    "print(params)\n",
    "\n",
    "data_params = {\n",
    "#     'max_bin':127,\n",
    "#     'enable_bundle': False,\n",
    "}\n",
    "print(data_params)\n",
    "\n",
    "num_round = 5000\n",
    "print('num_round:', num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T05:09:16.060736Z",
     "start_time": "2020-02-04T05:09:16.058171Z"
    }
   },
   "outputs": [],
   "source": [
    "# init_model = joblib.load('model/20200129T111708_0.27524341757899773.model')\n",
    "\n",
    "# 0.02x overfit 0.805803\n",
    "\n",
    "# 0.08323 0.635796\n",
    "# 0.174632 0.727734\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T08:11:58.579488Z",
     "start_time": "2020-02-04T05:09:16.236592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a088d0b89e645bda3c389ba208abc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='CV', max=10, style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37260, 100) (4140, 100)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 2.94187\tvalid_1's multi_logloss: 3.12158\n",
      "[100]\ttraining's multi_logloss: 2.33382\tvalid_1's multi_logloss: 2.62727\n",
      "[150]\ttraining's multi_logloss: 1.96262\tvalid_1's multi_logloss: 2.34381\n",
      "[200]\ttraining's multi_logloss: 1.70371\tvalid_1's multi_logloss: 2.15565\n",
      "[250]\ttraining's multi_logloss: 1.51082\tvalid_1's multi_logloss: 2.0222\n",
      "[300]\ttraining's multi_logloss: 1.36142\tvalid_1's multi_logloss: 1.9246\n",
      "[350]\ttraining's multi_logloss: 1.24331\tvalid_1's multi_logloss: 1.8528\n",
      "[400]\ttraining's multi_logloss: 1.14644\tvalid_1's multi_logloss: 1.7986\n",
      "[450]\ttraining's multi_logloss: 1.06543\tvalid_1's multi_logloss: 1.75584\n",
      "[500]\ttraining's multi_logloss: 0.996124\tvalid_1's multi_logloss: 1.7207\n",
      "[550]\ttraining's multi_logloss: 0.937156\tvalid_1's multi_logloss: 1.69325\n",
      "[600]\ttraining's multi_logloss: 0.886775\tvalid_1's multi_logloss: 1.67181\n",
      "[650]\ttraining's multi_logloss: 0.841671\tvalid_1's multi_logloss: 1.65394\n",
      "[700]\ttraining's multi_logloss: 0.802689\tvalid_1's multi_logloss: 1.64019\n",
      "[750]\ttraining's multi_logloss: 0.76702\tvalid_1's multi_logloss: 1.62888\n",
      "[800]\ttraining's multi_logloss: 0.735054\tvalid_1's multi_logloss: 1.61914\n",
      "[850]\ttraining's multi_logloss: 0.705355\tvalid_1's multi_logloss: 1.61105\n",
      "[900]\ttraining's multi_logloss: 0.677918\tvalid_1's multi_logloss: 1.60414\n",
      "[950]\ttraining's multi_logloss: 0.653176\tvalid_1's multi_logloss: 1.5997\n",
      "[1000]\ttraining's multi_logloss: 0.630037\tvalid_1's multi_logloss: 1.59555\n",
      "[1050]\ttraining's multi_logloss: 0.608833\tvalid_1's multi_logloss: 1.59301\n",
      "[1100]\ttraining's multi_logloss: 0.589761\tvalid_1's multi_logloss: 1.59165\n",
      "[1150]\ttraining's multi_logloss: 0.57163\tvalid_1's multi_logloss: 1.5909\n",
      "[1200]\ttraining's multi_logloss: 0.554229\tvalid_1's multi_logloss: 1.59008\n",
      "[1250]\ttraining's multi_logloss: 0.538007\tvalid_1's multi_logloss: 1.58969\n",
      "[1300]\ttraining's multi_logloss: 0.522958\tvalid_1's multi_logloss: 1.59054\n",
      "[1350]\ttraining's multi_logloss: 0.508507\tvalid_1's multi_logloss: 1.59123\n",
      "[1400]\ttraining's multi_logloss: 0.495226\tvalid_1's multi_logloss: 1.59275\n",
      "[1450]\ttraining's multi_logloss: 0.482031\tvalid_1's multi_logloss: 1.59352\n",
      "Early stopping, best iteration is:\n",
      "[1253]\ttraining's multi_logloss: 0.5371\tvalid_1's multi_logloss: 1.58955\n",
      "20200204T140915_0_1.5895526011977565_0.5371003766407364\n",
      "id\n",
      "828     1.0\n",
      "829     1.0\n",
      "830     1.0\n",
      "831     1.0\n",
      "832     1.0\n",
      "       ... \n",
      "1543    1.0\n",
      "1544    1.0\n",
      "1545    1.0\n",
      "1546    1.0\n",
      "1547    1.0\n",
      "Length: 720, dtype: float64\n",
      "           0         1         2         3         4         5         6    \\\n",
      "id                                                                           \n",
      "828   0.000057  0.000063  0.000071  0.000179  0.000104  0.000116  0.000135   \n",
      "829   0.000105  0.000094  0.000112  0.000207  0.000123  0.000123  0.000208   \n",
      "830   0.000165  0.000295  0.000271  0.000701  0.000339  0.000549  0.000445   \n",
      "831   0.000143  0.000090  0.000110  0.000260  0.004445  0.003375  0.000908   \n",
      "832   0.000072  0.000177  0.000112  0.000425  0.000124  0.000163  0.000195   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1543  0.001578  0.001187  0.001930  0.003784  0.001239  0.001182  0.001631   \n",
      "1544  0.000730  0.000570  0.000704  0.002032  0.000806  0.001036  0.001254   \n",
      "1545  0.000960  0.000876  0.001585  0.002829  0.001313  0.001208  0.001857   \n",
      "1546  0.000096  0.000099  0.000111  0.000346  0.000185  0.000185  0.000139   \n",
      "1547  0.000399  0.000666  0.000487  0.001897  0.000755  0.001050  0.001078   \n",
      "\n",
      "           7         8         9    ...       188       189       190  \\\n",
      "id                                  ...                                 \n",
      "828   0.000079  0.000030  0.000343  ...  0.000014  0.000009  0.000048   \n",
      "829   0.000139  0.000055  0.000446  ...  0.000019  0.000026  0.000018   \n",
      "830   0.000298  0.000146  0.001345  ...  0.000048  0.000045  0.000036   \n",
      "831   0.000854  0.000017  0.000307  ...  0.000007  0.000010  0.000007   \n",
      "832   0.000093  0.000073  0.000536  ...  0.000016  0.000012  0.000013   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1543  0.001498  0.000308  0.006580  ...  0.000250  0.000419  0.000207   \n",
      "1544  0.000987  0.000335  0.007079  ...  0.302409  0.000166  0.001494   \n",
      "1545  0.001771  0.000433  0.009938  ...  0.000384  0.000431  0.000352   \n",
      "1546  0.000157  0.000058  0.000747  ...  0.000028  0.000031  0.000018   \n",
      "1547  0.000652  0.000349  0.003171  ...  0.000113  0.000082  0.000068   \n",
      "\n",
      "           191       192       193       194       195       196       197  \n",
      "id                                                                          \n",
      "828   0.000008  0.000330  0.000110  0.000011  0.000015  0.000011  0.000015  \n",
      "829   0.000016  0.000617  0.000150  0.000019  0.000025  0.000012  0.000018  \n",
      "830   0.000039  0.001348  0.000411  0.000082  0.000074  0.000037  0.000070  \n",
      "831   0.000006  0.000263  0.000361  0.000011  0.000007  0.000004  0.000012  \n",
      "832   0.000012  0.000497  0.000194  0.000026  0.000037  0.000025  0.000022  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1543  0.000496  0.009702  0.003335  0.000348  0.000239  0.000067  0.000431  \n",
      "1544  0.000186  0.007710  0.002701  0.000367  0.000345  0.000092  0.000397  \n",
      "1545  0.000554  0.010349  0.004072  0.000536  0.000238  0.000067  0.000696  \n",
      "1546  0.000027  0.000599  0.000192  0.000029  0.000028  0.000014  0.000035  \n",
      "1547  0.000094  0.003331  0.001162  0.000151  0.000173  0.000181  0.000116  \n",
      "\n",
      "[720 rows x 198 columns]\n",
      "(37260, 100) (4140, 100)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 2.94496\tvalid_1's multi_logloss: 3.09816\n",
      "[100]\ttraining's multi_logloss: 2.34042\tvalid_1's multi_logloss: 2.59749\n",
      "[150]\ttraining's multi_logloss: 1.96797\tvalid_1's multi_logloss: 2.3061\n",
      "[200]\ttraining's multi_logloss: 1.707\tvalid_1's multi_logloss: 2.11179\n",
      "[250]\ttraining's multi_logloss: 1.51553\tvalid_1's multi_logloss: 1.97651\n",
      "[300]\ttraining's multi_logloss: 1.36651\tvalid_1's multi_logloss: 1.8779\n",
      "[350]\ttraining's multi_logloss: 1.2485\tvalid_1's multi_logloss: 1.80416\n",
      "[400]\ttraining's multi_logloss: 1.15139\tvalid_1's multi_logloss: 1.74706\n",
      "[450]\ttraining's multi_logloss: 1.07056\tvalid_1's multi_logloss: 1.7015\n",
      "[500]\ttraining's multi_logloss: 1.0021\tvalid_1's multi_logloss: 1.66668\n",
      "[550]\ttraining's multi_logloss: 0.94385\tvalid_1's multi_logloss: 1.6392\n",
      "[600]\ttraining's multi_logloss: 0.892899\tvalid_1's multi_logloss: 1.61685\n",
      "[650]\ttraining's multi_logloss: 0.847778\tvalid_1's multi_logloss: 1.59814\n",
      "[700]\ttraining's multi_logloss: 0.808284\tvalid_1's multi_logloss: 1.58416\n",
      "[750]\ttraining's multi_logloss: 0.771798\tvalid_1's multi_logloss: 1.57082\n",
      "[800]\ttraining's multi_logloss: 0.73983\tvalid_1's multi_logloss: 1.56116\n",
      "[850]\ttraining's multi_logloss: 0.710157\tvalid_1's multi_logloss: 1.55248\n",
      "[900]\ttraining's multi_logloss: 0.682413\tvalid_1's multi_logloss: 1.54511\n",
      "[950]\ttraining's multi_logloss: 0.657949\tvalid_1's multi_logloss: 1.54001\n",
      "[1000]\ttraining's multi_logloss: 0.634454\tvalid_1's multi_logloss: 1.53457\n",
      "[1050]\ttraining's multi_logloss: 0.612953\tvalid_1's multi_logloss: 1.53046\n",
      "[1100]\ttraining's multi_logloss: 0.593818\tvalid_1's multi_logloss: 1.52863\n",
      "[1150]\ttraining's multi_logloss: 0.575383\tvalid_1's multi_logloss: 1.52737\n",
      "[1200]\ttraining's multi_logloss: 0.558388\tvalid_1's multi_logloss: 1.52701\n",
      "[1250]\ttraining's multi_logloss: 0.541775\tvalid_1's multi_logloss: 1.52604\n",
      "[1300]\ttraining's multi_logloss: 0.526247\tvalid_1's multi_logloss: 1.52704\n",
      "[1350]\ttraining's multi_logloss: 0.513247\tvalid_1's multi_logloss: 1.52906\n",
      "[1400]\ttraining's multi_logloss: 0.499276\tvalid_1's multi_logloss: 1.52927\n",
      "Early stopping, best iteration is:\n",
      "[1249]\ttraining's multi_logloss: 0.542109\tvalid_1's multi_logloss: 1.52595\n",
      "20200204T140915_1_1.5259526335306355_0.5421085974832749\n",
      "id\n",
      "828     1.0\n",
      "829     1.0\n",
      "830     1.0\n",
      "831     1.0\n",
      "832     1.0\n",
      "       ... \n",
      "1543    1.0\n",
      "1544    1.0\n",
      "1545    1.0\n",
      "1546    1.0\n",
      "1547    1.0\n",
      "Length: 720, dtype: float64\n",
      "           0         1         2         3         4         5         6    \\\n",
      "id                                                                           \n",
      "828   0.000067  0.000098  0.000087  0.000226  0.000111  0.000146  0.000155   \n",
      "829   0.000092  0.000078  0.000095  0.000165  0.000140  0.000120  0.000159   \n",
      "830   0.000184  0.000294  0.000271  0.000751  0.000416  0.000550  0.000391   \n",
      "831   0.000086  0.000103  0.000174  0.000184  0.005229  0.003480  0.000721   \n",
      "832   0.000061  0.000153  0.000124  0.000272  0.000102  0.000133  0.000173   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1543  0.001468  0.001441  0.001851  0.003921  0.001349  0.001113  0.001441   \n",
      "1544  0.000935  0.000693  0.000912  0.001597  0.000804  0.000932  0.000992   \n",
      "1545  0.001064  0.001018  0.001485  0.002375  0.001363  0.001357  0.001380   \n",
      "1546  0.000106  0.000144  0.000132  0.000313  0.000229  0.000237  0.000138   \n",
      "1547  0.000444  0.000625  0.000515  0.002020  0.000844  0.001108  0.001025   \n",
      "\n",
      "           7         8         9    ...       188       189       190  \\\n",
      "id                                  ...                                 \n",
      "828   0.000175  0.000040  0.000346  ...  0.000027  0.000013  0.000022   \n",
      "829   0.000129  0.000053  0.000374  ...  0.000024  0.000015  0.000026   \n",
      "830   0.000361  0.000144  0.001226  ...  0.000047  0.000049  0.000048   \n",
      "831   0.000648  0.000013  0.000173  ...  0.000008  0.000008  0.000004   \n",
      "832   0.000081  0.000062  0.000368  ...  0.000016  0.000010  0.000011   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1543  0.001825  0.000297  0.006636  ...  0.000257  0.000609  0.000190   \n",
      "1544  0.000956  0.000348  0.007050  ...  0.281955  0.000204  0.002063   \n",
      "1545  0.002050  0.000428  0.010092  ...  0.000439  0.000530  0.000372   \n",
      "1546  0.000141  0.000066  0.000754  ...  0.000023  0.000023  0.000020   \n",
      "1547  0.000748  0.000359  0.003381  ...  0.000122  0.000077  0.000077   \n",
      "\n",
      "           191       192       193       194       195       196       197  \n",
      "id                                                                          \n",
      "828   0.000013  0.000474  0.000165  0.000017  0.000025  0.000011  0.000019  \n",
      "829   0.000017  0.000442  0.000202  0.000019  0.000018  0.000012  0.000026  \n",
      "830   0.000049  0.001176  0.000505  0.000077  0.000066  0.000040  0.000066  \n",
      "831   0.000007  0.000212  0.000135  0.000011  0.000006  0.000004  0.000011  \n",
      "832   0.000009  0.000481  0.000139  0.000023  0.000026  0.000024  0.000019  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1543  0.000279  0.007830  0.003358  0.000334  0.000190  0.000061  0.000302  \n",
      "1544  0.000151  0.008003  0.002091  0.000325  0.000290  0.000092  0.000550  \n",
      "1545  0.000366  0.011441  0.003972  0.000373  0.000266  0.000079  0.000986  \n",
      "1546  0.000024  0.000704  0.000242  0.000029  0.000032  0.000018  0.000029  \n",
      "1547  0.000092  0.003259  0.001354  0.000163  0.000282  0.000270  0.000128  \n",
      "\n",
      "[720 rows x 198 columns]\n",
      "(37260, 100) (4140, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 2.94219\tvalid_1's multi_logloss: 3.11191\n",
      "[100]\ttraining's multi_logloss: 2.336\tvalid_1's multi_logloss: 2.61555\n",
      "[150]\ttraining's multi_logloss: 1.96472\tvalid_1's multi_logloss: 2.32759\n",
      "[200]\ttraining's multi_logloss: 1.70432\tvalid_1's multi_logloss: 2.1369\n",
      "[250]\ttraining's multi_logloss: 1.51208\tvalid_1's multi_logloss: 2.00131\n",
      "[300]\ttraining's multi_logloss: 1.36105\tvalid_1's multi_logloss: 1.90161\n",
      "[350]\ttraining's multi_logloss: 1.24225\tvalid_1's multi_logloss: 1.82605\n",
      "[400]\ttraining's multi_logloss: 1.14588\tvalid_1's multi_logloss: 1.76919\n",
      "[450]\ttraining's multi_logloss: 1.06434\tvalid_1's multi_logloss: 1.72246\n",
      "[500]\ttraining's multi_logloss: 0.996036\tvalid_1's multi_logloss: 1.68656\n",
      "[550]\ttraining's multi_logloss: 0.937598\tvalid_1's multi_logloss: 1.65852\n",
      "[600]\ttraining's multi_logloss: 0.886098\tvalid_1's multi_logloss: 1.63494\n",
      "[650]\ttraining's multi_logloss: 0.841169\tvalid_1's multi_logloss: 1.61674\n",
      "[700]\ttraining's multi_logloss: 0.801206\tvalid_1's multi_logloss: 1.60151\n",
      "[750]\ttraining's multi_logloss: 0.765212\tvalid_1's multi_logloss: 1.58862\n",
      "[800]\ttraining's multi_logloss: 0.733018\tvalid_1's multi_logloss: 1.57777\n",
      "[850]\ttraining's multi_logloss: 0.703603\tvalid_1's multi_logloss: 1.57028\n",
      "[900]\ttraining's multi_logloss: 0.676354\tvalid_1's multi_logloss: 1.56286\n",
      "[950]\ttraining's multi_logloss: 0.651798\tvalid_1's multi_logloss: 1.55738\n",
      "[1000]\ttraining's multi_logloss: 0.628735\tvalid_1's multi_logloss: 1.55199\n",
      "[1050]\ttraining's multi_logloss: 0.60739\tvalid_1's multi_logloss: 1.54851\n",
      "[1100]\ttraining's multi_logloss: 0.588297\tvalid_1's multi_logloss: 1.5471\n",
      "[1150]\ttraining's multi_logloss: 0.570446\tvalid_1's multi_logloss: 1.54559\n",
      "[1200]\ttraining's multi_logloss: 0.553399\tvalid_1's multi_logloss: 1.54522\n",
      "[1250]\ttraining's multi_logloss: 0.536786\tvalid_1's multi_logloss: 1.54425\n",
      "[1300]\ttraining's multi_logloss: 0.521682\tvalid_1's multi_logloss: 1.54506\n",
      "[1350]\ttraining's multi_logloss: 0.507321\tvalid_1's multi_logloss: 1.54529\n",
      "[1400]\ttraining's multi_logloss: 0.49384\tvalid_1's multi_logloss: 1.54601\n",
      "[1450]\ttraining's multi_logloss: 0.480969\tvalid_1's multi_logloss: 1.54684\n",
      "Early stopping, best iteration is:\n",
      "[1270]\ttraining's multi_logloss: 0.530609\tvalid_1's multi_logloss: 1.54418\n",
      "20200204T140915_2_1.5441845099514901_0.5306089168258128\n",
      "id\n",
      "828     1.0\n",
      "829     1.0\n",
      "830     1.0\n",
      "831     1.0\n",
      "832     1.0\n",
      "       ... \n",
      "1543    1.0\n",
      "1544    1.0\n",
      "1545    1.0\n",
      "1546    1.0\n",
      "1547    1.0\n",
      "Length: 720, dtype: float64\n",
      "           0         1         2         3         4         5         6    \\\n",
      "id                                                                           \n",
      "828   0.000054  0.000052  0.000060  0.000143  0.000090  0.000095  0.000096   \n",
      "829   0.000085  0.000096  0.000101  0.000250  0.000105  0.000108  0.000158   \n",
      "830   0.000197  0.000341  0.000254  0.000683  0.000373  0.000567  0.000402   \n",
      "831   0.000116  0.000059  0.000151  0.000243  0.006200  0.003599  0.000634   \n",
      "832   0.000063  0.000112  0.000132  0.000313  0.000083  0.000128  0.000142   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1543  0.001373  0.001330  0.001813  0.003677  0.001334  0.001210  0.001621   \n",
      "1544  0.000638  0.000543  0.000734  0.001953  0.000795  0.000955  0.001145   \n",
      "1545  0.000916  0.001020  0.001548  0.002822  0.001167  0.001382  0.001653   \n",
      "1546  0.000104  0.000114  0.000166  0.000323  0.000174  0.000205  0.000173   \n",
      "1547  0.000387  0.000719  0.000516  0.001806  0.000788  0.001029  0.001200   \n",
      "\n",
      "           7         8         9    ...       188       189       190  \\\n",
      "id                                  ...                                 \n",
      "828   0.000087  0.000027  0.000252  ...  0.000014  0.000008  0.000013   \n",
      "829   0.000151  0.000050  0.000375  ...  0.000019  0.000016  0.000019   \n",
      "830   0.000328  0.000137  0.001370  ...  0.000047  0.000033  0.000040   \n",
      "831   0.000610  0.000013  0.000268  ...  0.000012  0.000005  0.000007   \n",
      "832   0.000071  0.000058  0.000484  ...  0.000014  0.000008  0.000013   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1543  0.001768  0.000301  0.006534  ...  0.000232  0.000422  0.000235   \n",
      "1544  0.001024  0.000315  0.007246  ...  0.292534  0.000185  0.001756   \n",
      "1545  0.001830  0.000405  0.009362  ...  0.000375  0.000554  0.000347   \n",
      "1546  0.000129  0.000057  0.000774  ...  0.000025  0.000018  0.000018   \n",
      "1547  0.000754  0.000325  0.003642  ...  0.000088  0.000079  0.000081   \n",
      "\n",
      "           191       192       193       194       195       196       197  \n",
      "id                                                                          \n",
      "828   0.000012  0.000411  0.000116  0.000011  0.000012  0.000009  0.000012  \n",
      "829   0.000018  0.000727  0.000200  0.000024  0.000025  0.000015  0.000026  \n",
      "830   0.000047  0.001152  0.000417  0.000063  0.000061  0.000045  0.000070  \n",
      "831   0.000006  0.000344  0.000159  0.000011  0.000007  0.000004  0.000011  \n",
      "832   0.000009  0.000466  0.000147  0.000021  0.000029  0.000027  0.000015  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1543  0.000342  0.010129  0.003574  0.000369  0.000216  0.000076  0.000471  \n",
      "1544  0.000179  0.008166  0.002533  0.000358  0.000273  0.000082  0.000513  \n",
      "1545  0.000390  0.012569  0.003626  0.000410  0.000221  0.000076  0.000873  \n",
      "1546  0.000024  0.000658  0.000160  0.000028  0.000034  0.000018  0.000038  \n",
      "1547  0.000087  0.002944  0.000997  0.000130  0.000222  0.000242  0.000126  \n",
      "\n",
      "[720 rows x 198 columns]\n",
      "(37260, 100) (4140, 100)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 2.94594\tvalid_1's multi_logloss: 3.10194\n",
      "[100]\ttraining's multi_logloss: 2.33658\tvalid_1's multi_logloss: 2.60232\n",
      "[150]\ttraining's multi_logloss: 1.96537\tvalid_1's multi_logloss: 2.31435\n",
      "[200]\ttraining's multi_logloss: 1.70559\tvalid_1's multi_logloss: 2.12343\n",
      "[250]\ttraining's multi_logloss: 1.51352\tvalid_1's multi_logloss: 1.98957\n",
      "[300]\ttraining's multi_logloss: 1.36387\tvalid_1's multi_logloss: 1.8913\n",
      "[350]\ttraining's multi_logloss: 1.24544\tvalid_1's multi_logloss: 1.81706\n",
      "[400]\ttraining's multi_logloss: 1.14814\tvalid_1's multi_logloss: 1.75995\n",
      "[450]\ttraining's multi_logloss: 1.06694\tvalid_1's multi_logloss: 1.71541\n",
      "[500]\ttraining's multi_logloss: 0.998305\tvalid_1's multi_logloss: 1.68025\n",
      "[550]\ttraining's multi_logloss: 0.939874\tvalid_1's multi_logloss: 1.65259\n",
      "[600]\ttraining's multi_logloss: 0.888439\tvalid_1's multi_logloss: 1.63032\n",
      "[650]\ttraining's multi_logloss: 0.84337\tvalid_1's multi_logloss: 1.61262\n",
      "[700]\ttraining's multi_logloss: 0.803793\tvalid_1's multi_logloss: 1.59807\n",
      "[750]\ttraining's multi_logloss: 0.767824\tvalid_1's multi_logloss: 1.58664\n",
      "[800]\ttraining's multi_logloss: 0.735405\tvalid_1's multi_logloss: 1.57696\n",
      "[850]\ttraining's multi_logloss: 0.705974\tvalid_1's multi_logloss: 1.56939\n",
      "[900]\ttraining's multi_logloss: 0.678646\tvalid_1's multi_logloss: 1.56354\n",
      "[950]\ttraining's multi_logloss: 0.654758\tvalid_1's multi_logloss: 1.55938\n",
      "[1000]\ttraining's multi_logloss: 0.631441\tvalid_1's multi_logloss: 1.55536\n",
      "[1050]\ttraining's multi_logloss: 0.610098\tvalid_1's multi_logloss: 1.55181\n",
      "[1100]\ttraining's multi_logloss: 0.591003\tvalid_1's multi_logloss: 1.55062\n",
      "[1150]\ttraining's multi_logloss: 0.572754\tvalid_1's multi_logloss: 1.54967\n",
      "[1200]\ttraining's multi_logloss: 0.555148\tvalid_1's multi_logloss: 1.54917\n",
      "[1250]\ttraining's multi_logloss: 0.538688\tvalid_1's multi_logloss: 1.54832\n",
      "[1300]\ttraining's multi_logloss: 0.52342\tvalid_1's multi_logloss: 1.54956\n",
      "[1350]\ttraining's multi_logloss: 0.508727\tvalid_1's multi_logloss: 1.55044\n",
      "[1400]\ttraining's multi_logloss: 0.495019\tvalid_1's multi_logloss: 1.55167\n",
      "Early stopping, best iteration is:\n",
      "[1249]\ttraining's multi_logloss: 0.53901\tvalid_1's multi_logloss: 1.54829\n",
      "20200204T140915_3_1.5482879782427899_0.5390104924586612\n",
      "id\n",
      "828     1.0\n",
      "829     1.0\n",
      "830     1.0\n",
      "831     1.0\n",
      "832     1.0\n",
      "       ... \n",
      "1543    1.0\n",
      "1544    1.0\n",
      "1545    1.0\n",
      "1546    1.0\n",
      "1547    1.0\n",
      "Length: 720, dtype: float64\n",
      "           0         1         2         3         4         5         6    \\\n",
      "id                                                                           \n",
      "828   0.000062  0.000058  0.000071  0.000183  0.000116  0.000119  0.000108   \n",
      "829   0.000109  0.000122  0.000129  0.000228  0.000119  0.000109  0.000177   \n",
      "830   0.000204  0.000337  0.000343  0.000772  0.000364  0.000473  0.000341   \n",
      "831   0.000107  0.000116  0.000093  0.000278  0.003319  0.005542  0.000659   \n",
      "832   0.000121  0.000170  0.000133  0.000484  0.000122  0.000140  0.000188   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1543  0.001981  0.001370  0.001686  0.003714  0.001527  0.001302  0.001402   \n",
      "1544  0.000761  0.000690  0.000701  0.002022  0.000968  0.000886  0.000928   \n",
      "1545  0.001139  0.001040  0.001302  0.003166  0.001426  0.001216  0.001264   \n",
      "1546  0.000112  0.000143  0.000144  0.000289  0.000176  0.000165  0.000102   \n",
      "1547  0.000441  0.000731  0.000518  0.001971  0.000779  0.000959  0.000905   \n",
      "\n",
      "           7         8         9    ...       188       189       190  \\\n",
      "id                                  ...                                 \n",
      "828   0.000099  0.000027  0.000301  ...  0.000022  0.000012  0.000017   \n",
      "829   0.000129  0.000055  0.000381  ...  0.000020  0.000015  0.000019   \n",
      "830   0.000312  0.000146  0.001398  ...  0.000048  0.000042  0.000043   \n",
      "831   0.000674  0.000015  0.000368  ...  0.000006  0.000012  0.000008   \n",
      "832   0.000108  0.000070  0.000471  ...  0.000016  0.000013  0.000013   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1543  0.002081  0.000333  0.006461  ...  0.000349  0.000569  0.000276   \n",
      "1544  0.001044  0.000335  0.007203  ...  0.298140  0.000166  0.001825   \n",
      "1545  0.001735  0.000434  0.009149  ...  0.000397  0.000656  0.000440   \n",
      "1546  0.000142  0.000058  0.000634  ...  0.000023  0.000026  0.000017   \n",
      "1547  0.000715  0.000361  0.003587  ...  0.000113  0.000085  0.000080   \n",
      "\n",
      "           191       192       193       194       195       196       197  \n",
      "id                                                                          \n",
      "828   0.000011  0.000385  0.000101  0.000013  0.000015  0.000008  0.000012  \n",
      "829   0.000017  0.000430  0.000148  0.000023  0.000026  0.000013  0.000020  \n",
      "830   0.000039  0.001130  0.000517  0.000070  0.000077  0.000034  0.000065  \n",
      "831   0.000007  0.000229  0.000182  0.000010  0.000009  0.000004  0.000018  \n",
      "832   0.000013  0.000520  0.000177  0.000035  0.000032  0.000030  0.000027  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1543  0.000515  0.009654  0.003786  0.000326  0.000217  0.000074  0.000377  \n",
      "1544  0.000171  0.007135  0.002333  0.000337  0.000265  0.000108  0.000420  \n",
      "1545  0.000403  0.014666  0.004132  0.000496  0.000269  0.000072  0.000675  \n",
      "1546  0.000019  0.000593  0.000190  0.000030  0.000029  0.000021  0.000033  \n",
      "1547  0.000074  0.002861  0.001041  0.000137  0.000247  0.000165  0.000110  \n",
      "\n",
      "[720 rows x 198 columns]\n",
      "(37260, 100) (4140, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 2.94603\tvalid_1's multi_logloss: 3.1085\n",
      "[100]\ttraining's multi_logloss: 2.33705\tvalid_1's multi_logloss: 2.60525\n",
      "[150]\ttraining's multi_logloss: 1.96684\tvalid_1's multi_logloss: 2.31813\n",
      "[200]\ttraining's multi_logloss: 1.70584\tvalid_1's multi_logloss: 2.12636\n",
      "[250]\ttraining's multi_logloss: 1.51353\tvalid_1's multi_logloss: 1.99255\n",
      "[300]\ttraining's multi_logloss: 1.36374\tvalid_1's multi_logloss: 1.89454\n",
      "[350]\ttraining's multi_logloss: 1.24559\tvalid_1's multi_logloss: 1.82031\n",
      "[400]\ttraining's multi_logloss: 1.14934\tvalid_1's multi_logloss: 1.7646\n",
      "[450]\ttraining's multi_logloss: 1.06802\tvalid_1's multi_logloss: 1.71853\n",
      "[500]\ttraining's multi_logloss: 0.999138\tvalid_1's multi_logloss: 1.68407\n",
      "[550]\ttraining's multi_logloss: 0.939893\tvalid_1's multi_logloss: 1.65583\n",
      "[600]\ttraining's multi_logloss: 0.888261\tvalid_1's multi_logloss: 1.63218\n",
      "[650]\ttraining's multi_logloss: 0.843289\tvalid_1's multi_logloss: 1.61336\n",
      "[700]\ttraining's multi_logloss: 0.803815\tvalid_1's multi_logloss: 1.59902\n",
      "[750]\ttraining's multi_logloss: 0.767629\tvalid_1's multi_logloss: 1.58636\n",
      "[800]\ttraining's multi_logloss: 0.735684\tvalid_1's multi_logloss: 1.57729\n",
      "[850]\ttraining's multi_logloss: 0.706161\tvalid_1's multi_logloss: 1.56956\n",
      "[900]\ttraining's multi_logloss: 0.678822\tvalid_1's multi_logloss: 1.56311\n",
      "[950]\ttraining's multi_logloss: 0.654427\tvalid_1's multi_logloss: 1.55846\n",
      "[1000]\ttraining's multi_logloss: 0.631208\tvalid_1's multi_logloss: 1.55344\n",
      "[1050]\ttraining's multi_logloss: 0.609901\tvalid_1's multi_logloss: 1.55015\n",
      "[1100]\ttraining's multi_logloss: 0.590772\tvalid_1's multi_logloss: 1.54792\n",
      "[1150]\ttraining's multi_logloss: 0.573098\tvalid_1's multi_logloss: 1.54748\n",
      "[1200]\ttraining's multi_logloss: 0.556214\tvalid_1's multi_logloss: 1.54747\n",
      "[1250]\ttraining's multi_logloss: 0.539509\tvalid_1's multi_logloss: 1.54664\n",
      "[1300]\ttraining's multi_logloss: 0.524129\tvalid_1's multi_logloss: 1.54752\n",
      "[1350]\ttraining's multi_logloss: 0.509389\tvalid_1's multi_logloss: 1.5479\n",
      "[1400]\ttraining's multi_logloss: 0.495864\tvalid_1's multi_logloss: 1.54929\n",
      "[1450]\ttraining's multi_logloss: 0.482642\tvalid_1's multi_logloss: 1.55012\n",
      "Early stopping, best iteration is:\n",
      "[1250]\ttraining's multi_logloss: 0.539509\tvalid_1's multi_logloss: 1.54664\n",
      "20200204T140915_4_1.5466419652349475_0.5395089617988336\n",
      "id\n",
      "828     1.0\n",
      "829     1.0\n",
      "830     1.0\n",
      "831     1.0\n",
      "832     1.0\n",
      "       ... \n",
      "1543    1.0\n",
      "1544    1.0\n",
      "1545    1.0\n",
      "1546    1.0\n",
      "1547    1.0\n",
      "Length: 720, dtype: float64\n",
      "           0         1         2         3         4         5         6    \\\n",
      "id                                                                           \n",
      "828   0.000054  0.000054  0.000073  0.000163  0.000107  0.000100  0.000097   \n",
      "829   0.000082  0.000084  0.000113  0.000177  0.000126  0.000105  0.000144   \n",
      "830   0.000252  0.000308  0.000365  0.000719  0.000412  0.000534  0.000405   \n",
      "831   0.000155  0.000166  0.000169  0.000307  0.006286  0.006278  0.001231   \n",
      "832   0.000072  0.000110  0.000122  0.000289  0.000104  0.000129  0.000168   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1543  0.001581  0.001314  0.001506  0.004267  0.001364  0.000986  0.001448   \n",
      "1544  0.000857  0.000617  0.000861  0.001845  0.000819  0.000760  0.001169   \n",
      "1545  0.001168  0.000890  0.001417  0.002737  0.001348  0.001213  0.001609   \n",
      "1546  0.000117  0.000112  0.000185  0.000291  0.000175  0.000193  0.000125   \n",
      "1547  0.000502  0.000703  0.000604  0.001997  0.000852  0.000981  0.001064   \n",
      "\n",
      "           7         8         9    ...       188       189       190  \\\n",
      "id                                  ...                                 \n",
      "828   0.000097  0.000028  0.000265  ...  0.000012  0.000008  0.000025   \n",
      "829   0.000143  0.000052  0.000364  ...  0.000018  0.000015  0.000025   \n",
      "830   0.000406  0.000160  0.001489  ...  0.000053  0.000044  0.000037   \n",
      "831   0.000597  0.000019  0.000322  ...  0.000008  0.000013  0.000008   \n",
      "832   0.000087  0.000063  0.000362  ...  0.000013  0.000016  0.000013   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1543  0.001858  0.000302  0.006797  ...  0.000293  0.000489  0.000258   \n",
      "1544  0.001006  0.000330  0.008086  ...  0.300508  0.000197  0.001800   \n",
      "1545  0.001960  0.000431  0.009787  ...  0.000465  0.000673  0.000435   \n",
      "1546  0.000151  0.000059  0.000549  ...  0.000020  0.000029  0.000020   \n",
      "1547  0.000829  0.000380  0.003562  ...  0.000463  0.000094  0.000086   \n",
      "\n",
      "           191       192       193       194       195       196       197  \n",
      "id                                                                          \n",
      "828   0.000009  0.000307  0.000110  0.000012  0.000013  0.000009  0.000012  \n",
      "829   0.000017  0.000426  0.000156  0.000018  0.000023  0.000014  0.000023  \n",
      "830   0.000050  0.001144  0.000472  0.000065  0.000078  0.000044  0.000065  \n",
      "831   0.000008  0.000384  0.000176  0.000010  0.000007  0.000021  0.000013  \n",
      "832   0.000015  0.000491  0.000131  0.000020  0.000028  0.000028  0.000022  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1543  0.000227  0.008535  0.003422  0.000317  0.000214  0.000090  0.000432  \n",
      "1544  0.000142  0.007309  0.002400  0.000320  0.000257  0.000117  0.000501  \n",
      "1545  0.000383  0.011907  0.003828  0.000382  0.000234  0.000080  0.000793  \n",
      "1546  0.000027  0.000692  0.000156  0.000024  0.000034  0.000017  0.000033  \n",
      "1547  0.000103  0.003191  0.001057  0.000156  0.000224  0.000246  0.000130  \n",
      "\n",
      "[720 rows x 198 columns]\n",
      "(37260, 100) (4140, 100)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 2.94532\tvalid_1's multi_logloss: 3.11832\n",
      "[100]\ttraining's multi_logloss: 2.33819\tvalid_1's multi_logloss: 2.61977\n",
      "[150]\ttraining's multi_logloss: 1.96589\tvalid_1's multi_logloss: 2.33259\n",
      "[200]\ttraining's multi_logloss: 1.70493\tvalid_1's multi_logloss: 2.13781\n",
      "[250]\ttraining's multi_logloss: 1.51244\tvalid_1's multi_logloss: 2.00295\n",
      "[300]\ttraining's multi_logloss: 1.3631\tvalid_1's multi_logloss: 1.9049\n",
      "[350]\ttraining's multi_logloss: 1.24464\tvalid_1's multi_logloss: 1.83165\n",
      "[400]\ttraining's multi_logloss: 1.14742\tvalid_1's multi_logloss: 1.77518\n",
      "[450]\ttraining's multi_logloss: 1.06641\tvalid_1's multi_logloss: 1.72987\n",
      "[500]\ttraining's multi_logloss: 0.997106\tvalid_1's multi_logloss: 1.69413\n",
      "[550]\ttraining's multi_logloss: 0.938607\tvalid_1's multi_logloss: 1.66634\n",
      "[600]\ttraining's multi_logloss: 0.887663\tvalid_1's multi_logloss: 1.64419\n",
      "[650]\ttraining's multi_logloss: 0.842791\tvalid_1's multi_logloss: 1.62585\n",
      "[700]\ttraining's multi_logloss: 0.80346\tvalid_1's multi_logloss: 1.61102\n",
      "[750]\ttraining's multi_logloss: 0.767101\tvalid_1's multi_logloss: 1.5989\n",
      "[800]\ttraining's multi_logloss: 0.734856\tvalid_1's multi_logloss: 1.58863\n",
      "[850]\ttraining's multi_logloss: 0.70503\tvalid_1's multi_logloss: 1.58042\n",
      "[900]\ttraining's multi_logloss: 0.677693\tvalid_1's multi_logloss: 1.57341\n",
      "[950]\ttraining's multi_logloss: 0.653288\tvalid_1's multi_logloss: 1.56832\n",
      "[1000]\ttraining's multi_logloss: 0.630235\tvalid_1's multi_logloss: 1.5638\n",
      "[1050]\ttraining's multi_logloss: 0.609078\tvalid_1's multi_logloss: 1.56162\n",
      "[1100]\ttraining's multi_logloss: 0.590069\tvalid_1's multi_logloss: 1.55981\n",
      "[1150]\ttraining's multi_logloss: 0.571771\tvalid_1's multi_logloss: 1.55772\n",
      "[1200]\ttraining's multi_logloss: 0.55446\tvalid_1's multi_logloss: 1.55705\n",
      "[1250]\ttraining's multi_logloss: 0.538207\tvalid_1's multi_logloss: 1.55671\n",
      "[1300]\ttraining's multi_logloss: 0.522956\tvalid_1's multi_logloss: 1.55751\n",
      "[1350]\ttraining's multi_logloss: 0.50835\tvalid_1's multi_logloss: 1.55821\n",
      "[1400]\ttraining's multi_logloss: 0.494566\tvalid_1's multi_logloss: 1.55941\n",
      "[1450]\ttraining's multi_logloss: 0.481548\tvalid_1's multi_logloss: 1.56089\n",
      "Early stopping, best iteration is:\n",
      "[1253]\ttraining's multi_logloss: 0.537193\tvalid_1's multi_logloss: 1.55659\n",
      "20200204T140915_5_1.5565937720316882_0.537193399673726\n",
      "id\n",
      "828     1.0\n",
      "829     1.0\n",
      "830     1.0\n",
      "831     1.0\n",
      "832     1.0\n",
      "       ... \n",
      "1543    1.0\n",
      "1544    1.0\n",
      "1545    1.0\n",
      "1546    1.0\n",
      "1547    1.0\n",
      "Length: 720, dtype: float64\n",
      "           0         1         2         3         4         5         6    \\\n",
      "id                                                                           \n",
      "828   0.000044  0.000061  0.000068  0.000178  0.000121  0.000116  0.000121   \n",
      "829   0.000070  0.000091  0.000113  0.000236  0.000102  0.000127  0.000132   \n",
      "830   0.000207  0.000356  0.000338  0.000661  0.000394  0.000514  0.000374   \n",
      "831   0.000088  0.000094  0.000130  0.000220  0.003560  0.004175  0.000714   \n",
      "832   0.000075  0.000162  0.000172  0.000359  0.000115  0.000154  0.000186   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1543  0.001625  0.001578  0.002691  0.005188  0.001296  0.001300  0.001329   \n",
      "1544  0.000788  0.000633  0.000909  0.002060  0.000858  0.001001  0.001048   \n",
      "1545  0.001162  0.001023  0.001688  0.002933  0.001415  0.001338  0.001412   \n",
      "1546  0.000092  0.000113  0.000166  0.000284  0.000197  0.000174  0.000113   \n",
      "1547  0.000414  0.000725  0.000538  0.001839  0.000792  0.000988  0.001043   \n",
      "\n",
      "           7         8         9    ...       188       189       190  \\\n",
      "id                                  ...                                 \n",
      "828   0.000102  0.000032  0.000325  ...  0.000034  0.000011  0.000034   \n",
      "829   0.000134  0.000054  0.000532  ...  0.000038  0.000017  0.000020   \n",
      "830   0.000385  0.000149  0.001417  ...  0.000046  0.000041  0.000049   \n",
      "831   0.000722  0.000015  0.000263  ...  0.000006  0.000006  0.000005   \n",
      "832   0.000107  0.000070  0.000458  ...  0.000015  0.000012  0.000014   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1543  0.001765  0.000311  0.006323  ...  0.000252  0.000553  0.000226   \n",
      "1544  0.001066  0.000336  0.007819  ...  0.288261  0.000190  0.001368   \n",
      "1545  0.001738  0.000424  0.009342  ...  0.000381  0.000583  0.000375   \n",
      "1546  0.000172  0.000060  0.000641  ...  0.000021  0.000020  0.000018   \n",
      "1547  0.000815  0.000356  0.003407  ...  0.000088  0.000087  0.000080   \n",
      "\n",
      "           191       192       193       194       195       196       197  \n",
      "id                                                                          \n",
      "828   0.000013  0.000329  0.000102  0.000012  0.000011  0.000010  0.000015  \n",
      "829   0.000013  0.000408  0.000150  0.000023  0.000023  0.000013  0.000025  \n",
      "830   0.000043  0.001215  0.000511  0.000057  0.000068  0.000045  0.000059  \n",
      "831   0.000013  0.000207  0.000193  0.000012  0.000007  0.000006  0.000018  \n",
      "832   0.000011  0.000489  0.000133  0.000018  0.000034  0.000052  0.000024  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1543  0.000399  0.008339  0.003086  0.000380  0.000239  0.000087  0.000393  \n",
      "1544  0.000166  0.007397  0.002587  0.000422  0.000288  0.000093  0.000443  \n",
      "1545  0.000509  0.011097  0.004184  0.000481  0.000262  0.000083  0.000781  \n",
      "1546  0.000024  0.000582  0.000199  0.000028  0.000037  0.000017  0.000030  \n",
      "1547  0.000073  0.003090  0.001017  0.000150  0.000199  0.000194  0.000123  \n",
      "\n",
      "[720 rows x 198 columns]\n",
      "(37260, 100) (4140, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 2.94279\tvalid_1's multi_logloss: 3.11742\n",
      "[100]\ttraining's multi_logloss: 2.33725\tvalid_1's multi_logloss: 2.61934\n",
      "[150]\ttraining's multi_logloss: 1.9657\tvalid_1's multi_logloss: 2.33116\n",
      "[200]\ttraining's multi_logloss: 1.70506\tvalid_1's multi_logloss: 2.14097\n",
      "[250]\ttraining's multi_logloss: 1.51216\tvalid_1's multi_logloss: 2.00579\n",
      "[300]\ttraining's multi_logloss: 1.36254\tvalid_1's multi_logloss: 1.90416\n",
      "[350]\ttraining's multi_logloss: 1.24373\tvalid_1's multi_logloss: 1.82767\n",
      "[400]\ttraining's multi_logloss: 1.14724\tvalid_1's multi_logloss: 1.77006\n",
      "[450]\ttraining's multi_logloss: 1.06627\tvalid_1's multi_logloss: 1.72451\n",
      "[500]\ttraining's multi_logloss: 0.997658\tvalid_1's multi_logloss: 1.68687\n",
      "[550]\ttraining's multi_logloss: 0.939572\tvalid_1's multi_logloss: 1.65827\n",
      "[600]\ttraining's multi_logloss: 0.888567\tvalid_1's multi_logloss: 1.63533\n",
      "[650]\ttraining's multi_logloss: 0.84328\tvalid_1's multi_logloss: 1.61646\n",
      "[700]\ttraining's multi_logloss: 0.804081\tvalid_1's multi_logloss: 1.60258\n",
      "[750]\ttraining's multi_logloss: 0.767895\tvalid_1's multi_logloss: 1.58942\n",
      "[800]\ttraining's multi_logloss: 0.736072\tvalid_1's multi_logloss: 1.57953\n",
      "[850]\ttraining's multi_logloss: 0.706519\tvalid_1's multi_logloss: 1.57161\n",
      "[900]\ttraining's multi_logloss: 0.679137\tvalid_1's multi_logloss: 1.56484\n",
      "[950]\ttraining's multi_logloss: 0.65445\tvalid_1's multi_logloss: 1.55853\n",
      "[1000]\ttraining's multi_logloss: 0.631336\tvalid_1's multi_logloss: 1.55418\n",
      "[1050]\ttraining's multi_logloss: 0.609941\tvalid_1's multi_logloss: 1.5511\n",
      "[1100]\ttraining's multi_logloss: 0.590894\tvalid_1's multi_logloss: 1.54916\n",
      "[1150]\ttraining's multi_logloss: 0.572636\tvalid_1's multi_logloss: 1.54779\n",
      "[1200]\ttraining's multi_logloss: 0.555797\tvalid_1's multi_logloss: 1.54706\n",
      "[1250]\ttraining's multi_logloss: 0.539246\tvalid_1's multi_logloss: 1.54641\n",
      "[1300]\ttraining's multi_logloss: 0.523888\tvalid_1's multi_logloss: 1.54632\n",
      "[1350]\ttraining's multi_logloss: 0.509373\tvalid_1's multi_logloss: 1.54703\n",
      "[1400]\ttraining's multi_logloss: 0.495641\tvalid_1's multi_logloss: 1.54728\n",
      "[1450]\ttraining's multi_logloss: 0.482562\tvalid_1's multi_logloss: 1.54875\n",
      "[1500]\ttraining's multi_logloss: 0.470303\tvalid_1's multi_logloss: 1.55088\n",
      "Early stopping, best iteration is:\n",
      "[1306]\ttraining's multi_logloss: 0.52202\tvalid_1's multi_logloss: 1.5461\n",
      "20200204T140915_6_1.546102549798417_0.5220204647947282\n",
      "id\n",
      "828     1.0\n",
      "829     1.0\n",
      "830     1.0\n",
      "831     1.0\n",
      "832     1.0\n",
      "       ... \n",
      "1543    1.0\n",
      "1544    1.0\n",
      "1545    1.0\n",
      "1546    1.0\n",
      "1547    1.0\n",
      "Length: 720, dtype: float64\n",
      "           0         1         2         3         4         5         6    \\\n",
      "id                                                                           \n",
      "828   0.000047  0.000050  0.000081  0.000193  0.000120  0.000110  0.000151   \n",
      "829   0.000072  0.000083  0.000116  0.000207  0.000119  0.000101  0.000171   \n",
      "830   0.000184  0.000289  0.000323  0.000890  0.000435  0.000538  0.000483   \n",
      "831   0.000083  0.000064  0.000159  0.000265  0.003648  0.005181  0.001369   \n",
      "832   0.000044  0.000099  0.000140  0.000262  0.000080  0.000101  0.000140   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1543  0.001321  0.001334  0.001863  0.003766  0.001443  0.001079  0.001813   \n",
      "1544  0.000651  0.000533  0.000812  0.001694  0.000939  0.000895  0.001099   \n",
      "1545  0.000883  0.000846  0.001531  0.002432  0.001416  0.001275  0.001607   \n",
      "1546  0.000088  0.000106  0.000145  0.000285  0.000204  0.000167  0.000157   \n",
      "1547  0.000391  0.000671  0.000524  0.002273  0.000853  0.001003  0.001067   \n",
      "\n",
      "           7         8         9    ...       188       189       190  \\\n",
      "id                                  ...                                 \n",
      "828   0.000139  0.000029  0.000306  ...  0.000015  0.000013  0.000024   \n",
      "829   0.000156  0.000047  0.000331  ...  0.000019  0.000016  0.000021   \n",
      "830   0.000308  0.000131  0.001378  ...  0.000051  0.000042  0.000039   \n",
      "831   0.000569  0.000013  0.000206  ...  0.000005  0.000010  0.000006   \n",
      "832   0.000066  0.000045  0.000300  ...  0.000072  0.000010  0.000007   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1543  0.001550  0.000275  0.006363  ...  0.000259  0.000508  0.000190   \n",
      "1544  0.000947  0.000291  0.007629  ...  0.304171  0.000173  0.001368   \n",
      "1545  0.001708  0.000375  0.009745  ...  0.001022  0.000659  0.000386   \n",
      "1546  0.000134  0.000050  0.000593  ...  0.000019  0.000024  0.000013   \n",
      "1547  0.000744  0.000316  0.003297  ...  0.000099  0.000090  0.000075   \n",
      "\n",
      "           191       192       193       194       195       196       197  \n",
      "id                                                                          \n",
      "828   0.000008  0.000501  0.000124  0.000014  0.000017  0.000009  0.000015  \n",
      "829   0.000015  0.000484  0.000197  0.000021  0.000016  0.000010  0.000030  \n",
      "830   0.000055  0.001357  0.000514  0.000107  0.000080  0.000043  0.000062  \n",
      "831   0.000004  0.000257  0.000162  0.000007  0.000008  0.000004  0.000010  \n",
      "832   0.000007  0.000358  0.000127  0.000015  0.000019  0.000019  0.000014  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1543  0.000319  0.009124  0.003535  0.000271  0.000228  0.000066  0.000389  \n",
      "1544  0.000147  0.007631  0.002318  0.000257  0.000305  0.000080  0.000529  \n",
      "1545  0.000350  0.010801  0.003944  0.000445  0.000218  0.000077  0.000859  \n",
      "1546  0.000024  0.000533  0.000169  0.000037  0.000031  0.000014  0.000024  \n",
      "1547  0.000082  0.003204  0.001020  0.000140  0.000195  0.000199  0.000114  \n",
      "\n",
      "[720 rows x 198 columns]\n",
      "(37260, 100) (4140, 100)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 2.94965\tvalid_1's multi_logloss: 3.09732\n",
      "[100]\ttraining's multi_logloss: 2.34276\tvalid_1's multi_logloss: 2.58919\n",
      "[150]\ttraining's multi_logloss: 1.97221\tvalid_1's multi_logloss: 2.29782\n",
      "[200]\ttraining's multi_logloss: 1.71316\tvalid_1's multi_logloss: 2.10597\n",
      "[250]\ttraining's multi_logloss: 1.51995\tvalid_1's multi_logloss: 1.97152\n",
      "[300]\ttraining's multi_logloss: 1.36847\tvalid_1's multi_logloss: 1.87035\n",
      "[350]\ttraining's multi_logloss: 1.24922\tvalid_1's multi_logloss: 1.79643\n",
      "[400]\ttraining's multi_logloss: 1.15177\tvalid_1's multi_logloss: 1.73802\n",
      "[450]\ttraining's multi_logloss: 1.07066\tvalid_1's multi_logloss: 1.69371\n",
      "[500]\ttraining's multi_logloss: 1.00171\tvalid_1's multi_logloss: 1.65793\n",
      "[550]\ttraining's multi_logloss: 0.943642\tvalid_1's multi_logloss: 1.62998\n",
      "[600]\ttraining's multi_logloss: 0.892248\tvalid_1's multi_logloss: 1.60681\n",
      "[650]\ttraining's multi_logloss: 0.84692\tvalid_1's multi_logloss: 1.58817\n",
      "[700]\ttraining's multi_logloss: 0.807545\tvalid_1's multi_logloss: 1.5738\n",
      "[750]\ttraining's multi_logloss: 0.771199\tvalid_1's multi_logloss: 1.56052\n",
      "[800]\ttraining's multi_logloss: 0.739259\tvalid_1's multi_logloss: 1.55089\n",
      "[850]\ttraining's multi_logloss: 0.709795\tvalid_1's multi_logloss: 1.54256\n",
      "[900]\ttraining's multi_logloss: 0.682126\tvalid_1's multi_logloss: 1.53488\n",
      "[950]\ttraining's multi_logloss: 0.657663\tvalid_1's multi_logloss: 1.52902\n",
      "[1000]\ttraining's multi_logloss: 0.634519\tvalid_1's multi_logloss: 1.52507\n",
      "[1050]\ttraining's multi_logloss: 0.612991\tvalid_1's multi_logloss: 1.52159\n",
      "[1100]\ttraining's multi_logloss: 0.593542\tvalid_1's multi_logloss: 1.51952\n",
      "[1150]\ttraining's multi_logloss: 0.574926\tvalid_1's multi_logloss: 1.51758\n",
      "[1200]\ttraining's multi_logloss: 0.557631\tvalid_1's multi_logloss: 1.5164\n",
      "[1250]\ttraining's multi_logloss: 0.540964\tvalid_1's multi_logloss: 1.51459\n",
      "[1300]\ttraining's multi_logloss: 0.525527\tvalid_1's multi_logloss: 1.51466\n",
      "[1350]\ttraining's multi_logloss: 0.510847\tvalid_1's multi_logloss: 1.5147\n",
      "[1400]\ttraining's multi_logloss: 0.497065\tvalid_1's multi_logloss: 1.51567\n",
      "[1450]\ttraining's multi_logloss: 0.483903\tvalid_1's multi_logloss: 1.5165\n",
      "[1500]\ttraining's multi_logloss: 0.471576\tvalid_1's multi_logloss: 1.51765\n",
      "Early stopping, best iteration is:\n",
      "[1310]\ttraining's multi_logloss: 0.522577\tvalid_1's multi_logloss: 1.51448\n",
      "20200204T140915_7_1.5144787791700651_0.5225773258953281\n",
      "id\n",
      "828     1.0\n",
      "829     1.0\n",
      "830     1.0\n",
      "831     1.0\n",
      "832     1.0\n",
      "       ... \n",
      "1543    1.0\n",
      "1544    1.0\n",
      "1545    1.0\n",
      "1546    1.0\n",
      "1547    1.0\n",
      "Length: 720, dtype: float64\n",
      "           0         1         2         3         4         5         6    \\\n",
      "id                                                                           \n",
      "828   0.000049  0.000048  0.000054  0.000158  0.000094  0.000076  0.000090   \n",
      "829   0.000064  0.000073  0.000112  0.000186  0.000130  0.000095  0.000156   \n",
      "830   0.000179  0.000276  0.000249  0.000898  0.000379  0.000514  0.000498   \n",
      "831   0.000147  0.000073  0.000127  0.000232  0.005041  0.006302  0.000763   \n",
      "832   0.000041  0.000108  0.000102  0.000294  0.000079  0.000102  0.000116   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1543  0.001197  0.001289  0.001843  0.005109  0.001380  0.001178  0.001468   \n",
      "1544  0.000607  0.000634  0.000704  0.001822  0.000857  0.000871  0.001076   \n",
      "1545  0.000880  0.000946  0.001478  0.003016  0.001491  0.001362  0.001561   \n",
      "1546  0.000120  0.000125  0.000126  0.000379  0.000153  0.000161  0.000158   \n",
      "1547  0.000382  0.000630  0.000459  0.002125  0.000772  0.000856  0.001086   \n",
      "\n",
      "           7         8         9    ...       188       189       190  \\\n",
      "id                                  ...                                 \n",
      "828   0.000100  0.000021  0.000240  ...  0.000022  0.000006  0.000023   \n",
      "829   0.000178  0.000045  0.000452  ...  0.000030  0.000013  0.000014   \n",
      "830   0.000342  0.000125  0.001451  ...  0.000101  0.000034  0.000033   \n",
      "831   0.000615  0.000012  0.000226  ...  0.000005  0.000005  0.000007   \n",
      "832   0.000080  0.000050  0.000399  ...  0.000013  0.000007  0.000010   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1543  0.001856  0.000270  0.006786  ...  0.000261  0.000389  0.000228   \n",
      "1544  0.001004  0.000276  0.007312  ...  0.309067  0.000145  0.001354   \n",
      "1545  0.001769  0.000365  0.009487  ...  0.000445  0.000434  0.000432   \n",
      "1546  0.000191  0.000051  0.000636  ...  0.000025  0.000020  0.000015   \n",
      "1547  0.000790  0.000295  0.003317  ...  0.000075  0.000074  0.000059   \n",
      "\n",
      "           191       192       193       194       195       196       197  \n",
      "id                                                                          \n",
      "828   0.000010  0.000556  0.000119  0.000008  0.000010  0.000007  0.000014  \n",
      "829   0.000013  0.000377  0.000121  0.000018  0.000018  0.000011  0.000017  \n",
      "830   0.000036  0.001141  0.000456  0.000055  0.000072  0.000032  0.000066  \n",
      "831   0.000007  0.000261  0.000158  0.000009  0.000006  0.000003  0.000012  \n",
      "832   0.000007  0.000388  0.000120  0.000078  0.000018  0.000039  0.000015  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1543  0.000294  0.009342  0.003348  0.000698  0.000162  0.000063  0.000326  \n",
      "1544  0.000144  0.008184  0.002402  0.001145  0.000212  0.000073  0.000415  \n",
      "1545  0.000330  0.011585  0.004287  0.000362  0.000185  0.000062  0.000772  \n",
      "1546  0.000017  0.000621  0.000188  0.000029  0.000024  0.000012  0.000029  \n",
      "1547  0.000075  0.003225  0.001071  0.000164  0.000178  0.000200  0.000122  \n",
      "\n",
      "[720 rows x 198 columns]\n",
      "(37260, 100) (4140, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's multi_logloss: 2.94593\tvalid_1's multi_logloss: 3.10889\n",
      "[100]\ttraining's multi_logloss: 2.33934\tvalid_1's multi_logloss: 2.60521\n",
      "[150]\ttraining's multi_logloss: 1.96747\tvalid_1's multi_logloss: 2.31474\n",
      "[200]\ttraining's multi_logloss: 1.70756\tvalid_1's multi_logloss: 2.11982\n",
      "[250]\ttraining's multi_logloss: 1.5145\tvalid_1's multi_logloss: 1.98516\n",
      "[300]\ttraining's multi_logloss: 1.36512\tvalid_1's multi_logloss: 1.8836\n",
      "[350]\ttraining's multi_logloss: 1.24647\tvalid_1's multi_logloss: 1.80778\n",
      "[400]\ttraining's multi_logloss: 1.14862\tvalid_1's multi_logloss: 1.74912\n",
      "[450]\ttraining's multi_logloss: 1.06773\tvalid_1's multi_logloss: 1.70342\n",
      "[500]\ttraining's multi_logloss: 0.999541\tvalid_1's multi_logloss: 1.66728\n",
      "[550]\ttraining's multi_logloss: 0.94146\tvalid_1's multi_logloss: 1.63919\n",
      "[600]\ttraining's multi_logloss: 0.890174\tvalid_1's multi_logloss: 1.61568\n",
      "[650]\ttraining's multi_logloss: 0.844671\tvalid_1's multi_logloss: 1.59622\n",
      "[700]\ttraining's multi_logloss: 0.805235\tvalid_1's multi_logloss: 1.58042\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0c855606bb5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                             \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                             \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m#                             init_model=model,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                            )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   2154\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \"\"\"\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2648\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = None\n",
    "submit_csv = []\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=81511991154 % 2**32-1, shuffle=True)\n",
    "\n",
    "cv = 0\n",
    "for train_index, valid_index in tqdm_notebook(skf.split(train.index, train['label'].values), total=n_splits, desc = 'CV'):\n",
    "#     cnt += 1\n",
    "#     print(cnt)\n",
    "#     if cnt < 3:\n",
    "#         continue\n",
    "\n",
    "    \n",
    "    X_train, X_test = train.loc[train_index, fea_cols], train.loc[valid_index, fea_cols] \n",
    "    y_train, y_test = train.loc[train_index,'label'], train.loc[valid_index, 'label']    \n",
    "    \n",
    "    print(X_train.shape, X_test.shape)\n",
    "#     print(y_train.value_counts(dropna=False))\n",
    "#     print(y_test.value_counts(dropna=False))\n",
    "    \n",
    "    \n",
    "    train_set = lgb.Dataset(X_train, label=y_train, params=data_params)\n",
    "    val_set = lgb.Dataset(X_test, label=y_test, params=data_params)\n",
    "\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, train_set, num_round, early_stopping_rounds=200, \n",
    "                            valid_sets=[train_set, val_set],\n",
    "                            verbose_eval=50,\n",
    "                            evals_result=evals_result,\n",
    "#                             init_model=model,\n",
    "                           )\n",
    "\n",
    "    model_tag ='{}_{}_{}_{}'.format(model_ts, cv,\n",
    "                                 evals_result['valid_1']['multi_logloss'][model.best_iteration-1],\n",
    "                                 evals_result['training']['multi_logloss'][model.best_iteration-1]\n",
    "                                )\n",
    "    print(model_tag)\n",
    "\n",
    "    joblib.dump(model, 'model/{}.model'.format(model_tag))\n",
    "    \n",
    "    \n",
    "    pred = model.predict(test[fea_cols])\n",
    "\n",
    "    submission = pd.DataFrame(data=pred)\n",
    "    submission.index = test.index\n",
    "    submission.index.name = 'id'\n",
    "    submission = submission.sort_index()\n",
    "    submission = submission.groupby('id').mean()\n",
    "\n",
    "    csv_path = 'submit/{}.csv'.format(model_tag)\n",
    "    submit_csv.append(csv_path)\n",
    "    submission.to_csv(    csv_path, index=True) \n",
    "    \n",
    "    print(submission.sum(axis=1))\n",
    "    print(submission)\n",
    "    cv += 1\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T08:11:58.580421Z",
     "start_time": "2020-02-04T05:09:16.924Z"
    }
   },
   "outputs": [],
   "source": [
    "# submissions = [\n",
    "# 'submit/20200201T193822_0.42165222105307115_0.03657010393259738.csv',\n",
    "# 'submit/20200201T183544_0.4354487978488266_0.04354968619883053.csv',\n",
    "# 'submit/20200201T173725_0.423066834354457_0.03614391993976106.csv',\n",
    "# 'submit/20200201T163343_0.4287587567261741_0.042392138498467166.csv',\n",
    "# 'submit/20200201T153529_0.42326652930531944_0.04098269988118284.csv',\n",
    "# 'submit/20200201T143616_0.4258237823312355_0.04651153387555587.csv',\n",
    "# 'submit/20200201T134047_0.43147156765580946_0.043682031170534714.csv',\n",
    "# 'submit/20200201T125939_0.42958065644660504_0.040012625819045466.csv',\n",
    "# 'submit/20200201T120739_0.42070899280425217_0.03477196302416032.csv',\n",
    "# 'submit/20200201T110556_0.4181683365658109_0.043843902710973416.csv',\n",
    "# ]\n",
    "\n",
    "\n",
    "dfs = [pd.read_csv(s) for s in submit_csv]\n",
    "\n",
    "df_submit = pd.concat(dfs)\n",
    "\n",
    "df_submit = df_submit.groupby('id').mean()\n",
    "\n",
    "df_submit.to_csv('submit/{}_e{}.csv'.format(model_ts, n_splits), index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T03:51:41.933456Z",
     "start_time": "2020-02-04T02:55:17.123Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submit.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T03:51:41.933875Z",
     "start_time": "2020-02-04T02:55:17.124Z"
    }
   },
   "outputs": [],
   "source": [
    "importance_type = 'split'\n",
    "impt_dict = {k:v for k, v in zip(fea_cols, model.feature_importance(importance_type=importance_type))}\n",
    "# sorted(impt_dict.items(), key=(lambda x:x[1]), reverse=True)\n",
    "# zero_cols = []\n",
    "for k, s in sorted(impt_dict.items(), key=(lambda x:x[1]), reverse=False):\n",
    "    if s == 0:\n",
    "        zero_cols.append(k)\n",
    "# joblib.dump(impt_dict, f'model/{file_name}_{importance_type}.pkl')\n",
    "\n",
    "len(zero_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T03:51:41.934281Z",
     "start_time": "2020-02-04T02:55:17.126Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(zero_cols, 'zero_cols.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T03:51:41.934676Z",
     "start_time": "2020-02-04T02:55:17.127Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = joblib.load('model/20200130T221520_2.4393985000913667_0.07225009557115544.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T03:51:41.935081Z",
     "start_time": "2020-02-04T02:55:17.129Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred = model.predict(test)\n",
    "\n",
    "# submission = pd.DataFrame(data=pred)\n",
    "# submission.index = test.index\n",
    "# submission.index.name = 'id'\n",
    "# submission = submission.sort_index()\n",
    "# submission = submission.groupby('id').mean()\n",
    "\n",
    "# submission.to_csv('submit/{}.csv'.format(model_tag), index=True) \n",
    "# model_tag\n",
    "\n",
    "# submission.sum(axis=1)\n",
    "\n",
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
